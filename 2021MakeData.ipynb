{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C₃₉'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subscript = ['₀', '₁', '₂', '₃', '₄', '₅', '₆', '₇', '₈', '₉']\n",
    "toUnicodeSubscript = lambda x: ''.join([subscript[int(char)] if char.isdigit() else char for char in x])\n",
    "toUnicodeSubscript('C39')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "import glob\n",
    "import numpy\n",
    "from PIL import ImageDraw \n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import ImageFont\n",
    "\n",
    "def loadResizeImage(img_path, label=None):\n",
    "    size = (124, 124)\n",
    "\n",
    "    # Load the image\n",
    "    img = Image.open(img_path)\n",
    "    # Keep the original image size\n",
    "    old_size = img.size\n",
    "\n",
    "    # Compute resizing ratio\n",
    "    ratio = float(size[0]) / max(old_size)\n",
    "    new_size = tuple([int(x * ratio) for x in old_size])\n",
    "\n",
    "    # Actually resize it\n",
    "    img = img.resize(new_size, Image.ANTIALIAS)\n",
    "\n",
    "    # Paste into centre of black padded image\n",
    "    new_img = Image.new(\"RGB\", (size[0], size[1]))\n",
    "    new_img.paste(img, ((size[0] - new_size[0]) // 2, (size[1] - new_size[1]) // 2))\n",
    "    if label != None:\n",
    "        draw = ImageDraw.Draw(new_img)\n",
    "        font = ImageFont.truetype(\"/System/Library/Fonts/Supplemental/Arial.ttf\", 12)\n",
    "        draw.text((62, 10),label,(255,255,255),font=font)\n",
    "\n",
    "    # Convert to numpy\n",
    "    new_img = numpy.array(new_img, dtype=numpy.uint8)\n",
    "\n",
    "    return new_img\n",
    "\n",
    "# Function to compose images in a grid\n",
    "compose = lambda images, horizontal: numpy.concatenate(\n",
    "    [img / 255 if horizontal == 1 else img for img in images],\n",
    "    axis=horizontal,\n",
    ")\n",
    "\n",
    "def listDirs(dir):\n",
    "    images = glob.glob(dir + '/*')\n",
    "    timestamps = [os.path.getctime(path) for path in images]\n",
    "    indeces = numpy.argsort(timestamps)\n",
    "    images = [images[idx] for idx in indeces]\n",
    "    return images, indeces\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip3 install xlsxwriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import xlsxwriter\n",
    "# import cv2\n",
    "# from io import BytesIO\n",
    "# # This sorts images based on timestamps. These are used to manually annotate the dataset.\n",
    "# topDir = '/Users/as16542/Downloads/10m32xl88x2b61zlkkgz3fml17/identification/images/test/*'\n",
    "# dirs = glob.glob(topDir)\n",
    "# for dir in dirs:\n",
    "#     img, indeces = listDirs(dir)\n",
    "#     # Create an new Excel file and add a worksheet.\n",
    "#     workbook = xlsxwriter.Workbook('./tracklets/{}.xlsx'.format(dir.split('/')[-1]))\n",
    "#     worksheet = workbook.add_worksheet()\n",
    "#     sheetFormat = workbook.add_format({'text_wrap': True})\n",
    "#     # Widen the first column to make the text clearer.\n",
    "#     worksheet.set_column('A:A', 30, sheetFormat)\n",
    "#     worksheet.set_column('B:B', 17)\n",
    "#     for i in range(len(img)):\n",
    "#         # Insert an image.\n",
    "#         worksheet.set_row(i, 92)\n",
    "#         success, img_numpy = cv2.imencode('.jpg', loadResizeImage(img[i], label=str(i)))\n",
    "#         worksheet.write('A{}'.format(i), img[i])\n",
    "#         worksheet.insert_image('B{}'.format(i), img[i], {'image_data': BytesIO(img_numpy.tobytes())})\n",
    "#     workbook.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# topDir = '/Users/as16542/Downloads/10m32xl88x2b61zlkkgz3fml17/identification/images/test/*'\n",
    "# dirs = glob.glob(topDir)\n",
    "# for dir in dirs:\n",
    "#     img, indeces = listDirs(dir)\n",
    "#     fig, ax = plt.subplots(1, figsize=((len(img) * 124)/500, 124/500), dpi=500)\n",
    "#     img = [loadResizeImage(img[i], label=str(i)) for i in range(len(img))]\n",
    "#     plt.imshow(compose(img, 1), aspect=1)\n",
    "#     [ax.spines[spine].set_visible(False) for spine in [\"top\", \"right\", \"bottom\", \"left\"]]\n",
    "#     ax.axes.get_xaxis().set_ticks([])\n",
    "#     ax.axes.get_yaxis().set_ticks([])\n",
    "#     ax.axis(\"tight\")\n",
    "#     # print(\"{} {}\".format(dir, len(img)))\n",
    "#     plt.savefig(\"./tracklets/{}.png\".format(dir.split('/')[-1]), dpi=500)\n",
    "#     plt.figure().clear()\n",
    "#     plt.close()\n",
    "#     plt.cla()\n",
    "#     plt.clf()\n",
    "#     # break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Open cows 2020 tracklets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import csv\n",
    "import numpy\n",
    "import json\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "# !pip3 install imblearn\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import random\n",
    "\n",
    "def listDirs(dir):\n",
    "    images = glob.glob(dir + '/*')\n",
    "    timestamps = [os.path.getctime(path) for path in images]\n",
    "    indeces = numpy.argsort(timestamps)\n",
    "    images = [images[idx] for idx in indeces]\n",
    "    return images, indeces\n",
    "\n",
    "def chunks(lst, n):\n",
    "    \"\"\"Yield successive n-sized chunks from lst.\"\"\"\n",
    "    for i in range(0, len(lst), n):\n",
    "        yield lst[i:i + n]\n",
    "\n",
    "topDir = './tracklets/train/csv/*'\n",
    "dirs = glob.glob(topDir)\n",
    "dataSet = {\"test\": [], \"train\": [], \"valid\": []}\n",
    "ignoreIndex = 1000\n",
    "for dir in dirs:\n",
    "    # Parse the train data\n",
    "    with open(dir) as csv_file:\n",
    "        csv_reader = csv.reader(csv_file, delimiter=',')\n",
    "        data = []\n",
    "        trackletInd = []\n",
    "        for row in csv_reader:\n",
    "            row[0] = row[0].replace('/Users/as16542/Downloads/10m32xl88x2b61zlkkgz3fml17/', '')\n",
    "            category = int(row[0].split('/')[-2])\n",
    "            if category < ignoreIndex:\n",
    "                data.append([row[0], category, int(row[1])])\n",
    "                trackletInd.append(int(row[1]))\n",
    "\n",
    "        dataRow = []\n",
    "        for i in range(len(numpy.unique(trackletInd))):\n",
    "            dataRow += [{'paths':[], 'label': ''}]\n",
    "        for path, category, tracklet in data:\n",
    "            dataRow[tracklet]['label'] = category\n",
    "            dataRow[tracklet]['paths'].append(path)\n",
    "        dataSet['train'] += dataRow\n",
    "\n",
    "# Append data from the test set file\n",
    "topDIR = '/Users/as16542/Downloads/10m32xl88x2b61zlkkgz3fml17/identification/images/test/'\n",
    "with open('utils/openCows2020_test_tracklet.json') as f:\n",
    "    files = json.load(f)\n",
    "    for file in files:\n",
    "        if file['type'] == 'split':\n",
    "            directories, indeces = listDirs(topDIR + file['cowID'])\n",
    "            for split in file['splits']:\n",
    "                if int(file['cowID']) < ignoreIndex:\n",
    "                    sortedIdx = [directories[idx].replace('/Users/as16542/Downloads/10m32xl88x2b61zlkkgz3fml17/', '') for idx in split]\n",
    "                    dataSet['train'].append({\"label\": int(file['cowID']), \"paths\": sortedIdx})\n",
    "        else:\n",
    "            if int(file['cowID']) < ignoreIndex:\n",
    "                directories, indeces = listDirs(topDIR + file['cowID'])\n",
    "                directories = [director.replace('/Users/as16542/Downloads/10m32xl88x2b61zlkkgz3fml17/', '') for director in directories]\n",
    "                dataSet['train'].append({\"label\": int(file['cowID']), \"paths\": directories})\n",
    "\n",
    "# Lets devide the sequences into smaller sequences of length 5\n",
    "data = []\n",
    "for tracklet in dataSet['train']:\n",
    "    label = tracklet['label'] - 1\n",
    "    subsequences = list(chunks(tracklet['paths'], 5))\n",
    "    sequences = []\n",
    "    for sequence in subsequences:\n",
    "        sequence = {'paths': sequence, 'label': label}\n",
    "        sequences.append(sequence)\n",
    "    data += sequences\n",
    "\n",
    "labels = [tracklet['label'] for tracklet in  data]\n",
    "\n",
    "# Add generate more data for the classes with loss number of samples\n",
    "classFrequency = numpy.zeros(numpy.unique(labels).shape)\n",
    "for track in data:\n",
    "    classFrequency[track['label']] += 1\n",
    "for classLabel, frequency in enumerate(classFrequency):\n",
    "    # get all samples from a label\n",
    "    samples = [track for track in data if track['label'] == classLabel]\n",
    "    # Merge all paths into a single list\n",
    "    paths = [path for track in samples for path in track['paths']]\n",
    "    # generate n tracks from the paths\n",
    "    randomSequences = []\n",
    "    for i in range((max(classFrequency) - frequency).astype(int)):\n",
    "        randomSequences.append({'paths': random.sample(paths, k=10), 'label': classLabel})\n",
    "    if len(randomSequences) > 0:\n",
    "        data += randomSequences\n",
    "\n",
    "# Get hte labels again\n",
    "labels = [tracklet['label'] for tracklet in  data]\n",
    "# Now let make the test and train split\n",
    "train, test, _, _ = train_test_split(data, labels, test_size=0.3, random_state=42, stratify=labels)\n",
    "dataSetFin = {\"test\": test, \"train\": train, \"valid\": []}\n",
    "# Generate k folds validation set\n",
    "sKFold = StratifiedKFold(n_splits=3, random_state=42, shuffle=True)\n",
    "i = 0\n",
    "# for train_index, test_index in sKFold.split(dataSetFin['train'], [tracklet['label'] for tracklet in  dataSetFin['train']]):\n",
    "for train_index, test_index in sKFold.split(data, labels):\n",
    "    train, test = [], []\n",
    "    for j in range(len(train_index)):\n",
    "        train.append(data[train_index[j]])\n",
    "    for j in range(len(test_index)):\n",
    "        test.append(data[test_index[j]])\n",
    "\n",
    "    dataSetFin['traink{}'.format(i)] = train\n",
    "    dataSetFin['testk{}'.format(i)] = test\n",
    "    i+=1\n",
    "\n",
    "import json\n",
    "# Save\n",
    "with open('./utils/opencowsTracklets2020.json', 'w') as fp:\n",
    "    json.dump(dataSetFin, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1080x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "classFrequency = numpy.zeros(numpy.unique(labels).shape)\n",
    "\n",
    "def labels_to_class_weights(labels, nc=80): \n",
    "    # Get class weights (inverse frequency) from training labels \n",
    "    classes = numpy.asarray(labels)\n",
    "    weights = numpy.bincount(classes, minlength=nc)  # occurences per class \n",
    "    weights[weights == 0] = 1  # replace empty bins with 1 \n",
    "    weights = 1 / weights  # number of targets per class \n",
    "    weights /= weights.sum()  # normalize \n",
    "    return weights\n",
    "\n",
    "for track in dataSetFin['traink1']:\n",
    "    classFrequency[track['label']] += 1\n",
    "\n",
    "# for track in data:\n",
    "#     classFrequency[track['label']] += 1\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (15, 5)\n",
    "width = 0.40\n",
    "x = numpy.unique(labels)\n",
    "ax = plt.axes()\n",
    "# plt.bar(x-0.2, classFrequency, width, color='cyan')\n",
    "plt.bar(x-0.2, classFrequency / numpy.sum(classFrequency), width, color='cyan')\n",
    "plt.bar(x+0.2, labels_to_class_weights(labels, nc=len(x)), width, color='green')\n",
    "\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(['$C_{{{}}}$'.format(i) for i in x])\n",
    "plt.xlabel(\"Individual\")\n",
    "plt.ylabel(\"Number of Samples\")\n",
    "plt.legend([\"Class frequency\", \"Weights\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "topDIR = '/Users/as16542/Downloads/10m32xl88x2b61zlkkgz3fml17/identification/images/train/'\n",
    "dataSet = {\"test\": [], \"train\": [], \"valid\": []}\n",
    "with open('utils/openCows2020_train_tracklet.json') as f:\n",
    "    files = json.load(f)\n",
    "    for file in files:\n",
    "        if file['type'] == 'split':\n",
    "            directories, indeces = listDirs(topDIR + file['cowID'])\n",
    "            for split in file['splits']:\n",
    "                sortedIdx = [directories[idx].replace('/Users/as16542/Downloads/10m32xl88x2b61zlkkgz3fml17/', '') for idx in split]\n",
    "                dataSet['train'].append({\"label\": int(file['cowID']), \"paths\": sortedIdx})\n",
    "        else:\n",
    "            directories, indeces = listDirs(topDIR + file['cowID'])\n",
    "            directories = [director.replace('/Users/as16542/Downloads/10m32xl88x2b61zlkkgz3fml17/', '') for director in directories]\n",
    "            dataSet['train'].append({\"label\": int(file['cowID']), \"paths\": directories})\n",
    "\n",
    "topDIR = '/Users/as16542/Downloads/10m32xl88x2b61zlkkgz3fml17/identification/images/test/'\n",
    "with open('utils/openCows2020_test_tracklet.json') as f:\n",
    "    files = json.load(f)\n",
    "    for file in files:\n",
    "        if file['type'] == 'split':\n",
    "            directories, indeces = listDirs(topDIR + file['cowID'])\n",
    "            for split in file['splits']:\n",
    "                sortedIdx = [directories[idx].replace('/Users/as16542/Downloads/10m32xl88x2b61zlkkgz3fml17/', '') for idx in split]\n",
    "                dataSet['test'].append({\"label\": int(file['cowID']), \"paths\": sortedIdx})\n",
    "        else:\n",
    "            directories, indeces = listDirs(topDIR + file['cowID'])\n",
    "            directories = [director.replace('/Users/as16542/Downloads/10m32xl88x2b61zlkkgz3fml17/', '') for director in directories]\n",
    "            dataSet['test'].append({\"label\": int(file['cowID']), \"paths\": directories})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = [len(track['paths']) for track in dataSet['test']]\n",
    "plt.plot(dt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2021 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "import glob\n",
    "import numpy\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def chunks(lst, n):\n",
    "    \"\"\"Yield successive n-sized chunks from lst.\"\"\"\n",
    "    for i in range(0, len(lst), n):\n",
    "        yield lst[i:i + n]\n",
    "\n",
    "def listDirs(dir):\n",
    "    images = glob.glob(dir + '/*')\n",
    "    timestamps = [os.path.getctime(path) for path in images]\n",
    "    indeces = numpy.argsort(timestamps)\n",
    "    images = [images[idx] for idx in indeces]\n",
    "    return images\n",
    "\n",
    "topDir = '/Users/as16542/Downloads/4vnrca7qw1642qlwxjadp87h7/Sub-levels/Identification/Train/RGBDCows2020/Identification/RGB'\n",
    "dataSet = {\"test\": [], \"train\": [], \"valid\": []}\n",
    "\n",
    "# Parse the train data\n",
    "with open('utils/correct.csv') as csv_file:\n",
    "    csv_reader = csv.reader(csv_file, delimiter=',')\n",
    "    line_count = 0\n",
    "    for row in csv_reader:\n",
    "        if line_count > 0 and line_count < 465 and row[6] != 'black':\n",
    "            label = row[4] if row[4] != '' else row[2]\n",
    "            if label != '':\n",
    "                dirs = [dir.replace('/Users/as16542/Downloads/4vnrca7qw1642qlwxjadp87h7/', '') for dir in listDirs(os.path.join(topDir, row[1]))]\n",
    "                # Split into smaller sequences\n",
    "                subsequences = list(chunks(dirs, 10))\n",
    "                subsequences = [\n",
    "                    {'paths': subsequence, 'label': int(label)}\n",
    "                    for subsequence in subsequences\n",
    "                ]\n",
    "                dataSet['train'] += subsequences\n",
    "        line_count += 1\n",
    "\n",
    "# Parse the test data\n",
    "labels = list(set([item['label'] for item in dataSet[\"train\"]]))\n",
    "topDir = '/Users/as16542/Downloads/4vnrca7qw1642qlwxjadp87h7/Sub-levels/Identification/Test/'\n",
    "for label in labels:\n",
    "    path = os.path.join(topDir, '{:>03}'.format(label))\n",
    "    dirs = [dir.replace('/Users/as16542/Downloads/4vnrca7qw1642qlwxjadp87h7/', '') for dir in listDirs(path)]\n",
    "    # Split into smaller sequences\n",
    "    subsequences = list(chunks(dirs, 10))\n",
    "    subsequences = [\n",
    "        {'paths': subsequence, 'label': int(label)}\n",
    "        for subsequence in subsequences\n",
    "    ]\n",
    "    dataSet['test'] += subsequences    \n",
    "    # dataSet[\"test\"].append({'label': int(label), 'paths': dirs})\n",
    "\n",
    "# Since we omitted black cows we need to remove some classes and reindex the labels again\n",
    "labels = list(set([item['label'] for item in dataSet[\"train\"]] + [item['label'] for item in dataSet[\"test\"]]))\n",
    "hotEncodeMap = {}\n",
    "for i in range(len(labels)):\n",
    "    hotEncodeMap[labels[i]] = i\n",
    "\n",
    "# Now we can use the map the relabel the dataset\n",
    "for split in dataSet.keys():\n",
    "    for i in range(len(dataSet[split])):\n",
    "        dataSet[split][i]['label'] = hotEncodeMap[dataSet[split][i]['label']]\n",
    "\n",
    "# Prepare for k-fold splits\n",
    "data = dataSet['train'] + dataSet['test']\n",
    "labels = [item['label'] for item in data]\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# Generate k folds validation set\n",
    "sKFold = StratifiedKFold(n_splits=3, random_state=None, shuffle=False)\n",
    "dataSetFin = {\"test\": [], \"train\": [], \"valid\": []}\n",
    "i = 0\n",
    "for train_index, test_index in sKFold.split(data, labels):\n",
    "    train, test = [], []\n",
    "    for j in range(len(train_index)):\n",
    "        train.append(data[train_index[j]])\n",
    "    for j in range(len(test_index)):\n",
    "        test.append(data[test_index[j]])\n",
    "    dataSetFin['traink{}'.format(i)] = train\n",
    "    dataSetFin['testk{}'.format(i)] = test\n",
    "    i+=1\n",
    "\n",
    "# Now let make the test and train split\n",
    "train, test, _, _ = train_test_split(data, labels, test_size=0.3, random_state=42, stratify=labels)\n",
    "dataSetFin['train'] = train\n",
    "dataSetFin['test'] = test\n",
    "\n",
    "import json\n",
    "# Save\n",
    "with open('./utils/opencowsTracklets2021.json', 'w') as fp:\n",
    "    json.dump(dataSetFin, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "classFrequency = numpy.zeros(numpy.unique(labels).shape)\n",
    "\n",
    "def labels_to_class_weights(labels, nc=80): \n",
    "    # Get class weights (inverse frequency) from training labels \n",
    "    classes = numpy.asarray(labels)\n",
    "    weights = numpy.bincount(classes, minlength=nc)  # occurences per class \n",
    "    weights[weights == 0] = 1  # replace empty bins with 1 \n",
    "    weights = 1 / weights  # number of targets per class \n",
    "    weights /= weights.sum()  # normalize \n",
    "    return weights\n",
    "\n",
    "for track in dataSetFin['traink0']:\n",
    "    classFrequency[track['label']] += 1\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (15, 5)\n",
    "width = 0.40\n",
    "x = numpy.unique(labels)\n",
    "ax = plt.axes()\n",
    "# plt.bar(x-0.2, classFrequency, width, color='cyan')\n",
    "plt.bar(x-0.2, classFrequency / numpy.sum(classFrequency), width, color='cyan')\n",
    "plt.bar(x+0.2, labels_to_class_weights(labels, nc=len(x)), width, color='green')\n",
    "\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(['$C_{{{}}}$'.format(i) for i in x])\n",
    "plt.xlabel(\"Individual\")\n",
    "plt.ylabel(\"Number of Samples\")\n",
    "plt.legend([\"Class frequency\", \"Weights\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Timestamp for 2021 dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from datetime import datetime\n",
    "\n",
    "def fp2timestamp(fp):\n",
    "    # Regex pattern to match the timestamp\n",
    "    pattern = r'_?(?P<YY>\\d{4})-(?P<MM>\\d{2})-(?P<DD>\\d{1,2})_(?P<hh>\\d{1,2})-(?P<mm>\\d{1,2})-(?P<ss>\\d{1,2})_(image_roi|roi)'\n",
    "    # Get groups\n",
    "    try:\n",
    "        p = list(re.finditer(pattern, fp))[0].groupdict()\n",
    "        # Convert to datetime object\n",
    "        p = f\"{p['YY']}-{p['MM']}-{(p['DD'])}T{p['hh']}::{p['mm']}::{p['ss']}\"\n",
    "        return datetime.timestamp(datetime.strptime(p, '%Y-%m-%dT%H::%M::%S'))\n",
    "    except IndexError:\n",
    "        return 0\n",
    "for tracklet in dataSet['train']:\n",
    "    [fp2timestamp(path) for path in tracklet['paths']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def loadResizeImage(img_path):\n",
    "    size = (244, 244)\n",
    "    # Load the image\n",
    "    img = Image.open(img_path)\n",
    "\n",
    "    # Keep the original image size\n",
    "    old_size = img.size\n",
    "\n",
    "    # Compute resizing ratio\n",
    "    ratio = float(size[0]) / max(old_size)\n",
    "    new_size = tuple([int(x * ratio) for x in old_size])\n",
    "\n",
    "    # Actually resize it\n",
    "    img = img.resize(new_size, Image.ANTIALIAS)\n",
    "\n",
    "    # Paste into centre of black padded image\n",
    "    new_img = Image.new(\"RGB\", (size[0], size[1]))\n",
    "    new_img.paste(img, ((size[0] - new_size[0]) // 2, (size[1] - new_size[1]) // 2))\n",
    "\n",
    "    # Convert to numpy\n",
    "    new_img = numpy.array(new_img, dtype=numpy.uint8)\n",
    "\n",
    "    return new_img\n",
    "\n",
    "# Function to compose images in a grid\n",
    "compose = lambda images, horizontal: numpy.concatenate(\n",
    "    [img / 255 if horizontal == 1 else img for img in images],\n",
    "    axis=horizontal,\n",
    ")\n",
    "\n",
    "topDir = \"/Users/as16542/Downloads/10m32xl88x2b61zlkkgz3fml17\"\n",
    "for i in range(38, 39):\n",
    "    # Sample image from the dataset\n",
    "    trainSet = None\n",
    "    testSet = None\n",
    "    negSet = None\n",
    "    for j in range(len(dataSet[\"train\"])):\n",
    "        if dataSet[\"train\"][j][\"label\"] - 1 == i:\n",
    "            trainSet = dataSet[\"train\"][j][\"paths\"]\n",
    "            break\n",
    "    for j in range(len(dataSet[\"test\"])):\n",
    "        if dataSet[\"test\"][j][\"label\"] - 1 == i:\n",
    "            testSet = dataSet[\"test\"][j][\"paths\"]\n",
    "            break\n",
    "    for j in range(len(dataSet[\"test\"])):\n",
    "        if dataSet[\"test\"][j][\"label\"] - 1 == i+1:\n",
    "            negSet = dataSet[\"test\"][j][\"paths\"]\n",
    "            break\n",
    "    # Take first 5 images\n",
    "    trainSet, testSet, negSet = [os.path.join(topDir, path) for path in trainSet[:5]], [\n",
    "        os.path.join(topDir, path) for path in testSet[:5]\n",
    "    ], [os.path.join(topDir, path) for path in negSet[:5]]\n",
    "\n",
    "    trainSet, testSet = [loadResizeImage(path) for path in trainSet], [loadResizeImage(path) for path in testSet]\n",
    "    negSet = [loadResizeImage(path) for path in negSet]\n",
    "    print(len(trainSet), len(testSet), len(negSet))\n",
    "    composite = compose([compose(trainSet, 1), compose(testSet, 1), compose(negSet, 1)], 0)\n",
    "    plt.imshow(composite)\n",
    "    plt.show()\n",
    "    print(i)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = (10, 10)\n",
    "fig, ax = plt.subplots(1, dpi=100)\n",
    "found = []\n",
    "for item in dataSet['train']:\n",
    "    if item['label'] == 1:\n",
    "        found.append(item)\n",
    "\n",
    "# Take first 5 images\n",
    "trainSet, testSet = [os.path.join(topDir, path) for path in found[0]['paths'][:5]], [\n",
    "    os.path.join(topDir, path) for path in found[1]['paths'][:5]\n",
    "]\n",
    "\n",
    "trainSet, testSet = [loadResizeImage(path) for path in trainSet], [loadResizeImage(path) for path in testSet]\n",
    "composite = compose([compose(trainSet, 1), compose(testSet, 1)], 0)\n",
    "plt.imshow(composite)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "# Save\n",
    "with open('./utils/opencowsTracklets2020V2.json', 'w') as fp:\n",
    "    json.dump(dataSet, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = [len(track['paths']) for track in dataSet['train']]\n",
    "plt.plot(dt)\n",
    "sum(dt) / len(dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.model_zoo as model_zoo\n",
    "import torchvision.models as models\n",
    "import hiddenlayer as hl\n",
    "from tqdm import tqdm\n",
    "from torch import optim\n",
    "import numpy\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from utils.OpenSetCows2021 import OpenSetCows2021TrackLet\n",
    "\n",
    "dataset = OpenSetCows2021TrackLet(\n",
    "    \"/Users/as16542/Downloads/10m32xl88x2b61zlkkgz3fml17\",\n",
    "    \"utils/opencowsTracklets2020V2.json\",\n",
    "    maxSequenceLength=None,\n",
    "    transform=False,\n",
    "    split=\"train\",\n",
    "    trackletChoiceProb = 1,\n",
    ")\n",
    "\n",
    "dataset2 = OpenSetCows2021TrackLet(\n",
    "    \"/Users/as16542/Downloads/10m32xl88x2b61zlkkgz3fml17\",\n",
    "    \"utils/opencowsTracklets2020V2.json\",\n",
    "    maxSequenceLength=None,\n",
    "    transform=False,\n",
    "    split=\"test\",\n",
    "    trackletChoiceProb = 1,\n",
    ")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams[\"figure.figsize\"] = (15, 5)\n",
    "fig = plt.figure()\n",
    "ax = fig.add_axes([0,0,1,1])\n",
    "\n",
    "distribution = numpy.asarray([[k, len(dataset.lookup[k])] for k in dataset.lookup.keys()])\n",
    "distribution2 = numpy.asarray([[k, len(dataset2.lookup[k])] for k in dataset2.lookup.keys()])\n",
    "langs = [str(i) for i in distribution[:,0]]\n",
    "students = distribution[:,1]\n",
    "ax.bar(langs,students)\n",
    "ax.bar(langs,distribution2[:,1])\n",
    "plt.show()\n",
    "\n",
    "dataset3 = OpenSetCows2021TrackLet(\n",
    "    \"/Users/as16542/Downloads/10m32xl88x2b61zlkkgz3fml17\",\n",
    "    \"utils/opencowsTracklets2020V2Combined.json\",\n",
    "    maxSequenceLength=None,\n",
    "    # transform=False,\n",
    "    split=\"train\",\n",
    "    trackletChoiceProb = 1,\n",
    ")\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_axes([0,0,1,1])\n",
    "distribution = numpy.asarray([[k, len(dataset3.lookup[k])] for k in dataset3.lookup.keys()])\n",
    "langs = [str(i) for i in distribution[:,0]]\n",
    "students = distribution[:,1]\n",
    "ax.bar(langs,students)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequenceLengths = [[dataset3.__getitem__(ind)[0].shape[0] for ind in dataset3.lookup[k]] for k in dataset3.lookup.keys()]\n",
    "sequenceLengths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make k-fold validation dataset for AirealCows 2017"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, glob\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "topDIR = '/Users/as16542/Downloads/3owflku95bxsx24643cybxu3qh/*/*/*.jpg'\n",
    "dataSet = {\"test\": [], \"train\": [], \"valid\": []}\n",
    "images = glob.glob(topDIR)\n",
    "images.sort()\n",
    "currentCategory, currentTracklet = 0, 0\n",
    "currentList, trackletImage = [], []\n",
    "element = {}\n",
    "categories = []\n",
    "for directory in images:\n",
    "    elements = directory.split('/')\n",
    "    category, tracklet, image = int(elements[-3]), int(elements[-2]), elements[-1]\n",
    "    if currentCategory != category or currentTracklet != tracklet:\n",
    "        dataSet['train'].append({'paths': trackletImage, 'label': currentCategory})\n",
    "        trackletImage = []\n",
    "        categories.append(category)\n",
    "        currentCategory = category\n",
    "        currentTracklet = tracklet\n",
    "    # if category > 1:\n",
    "    #     break\n",
    "    trackletImage.append(directory.replace('/Users/as16542/Downloads/3owflku95bxsx24643cybxu3qh/', ''))\n",
    "\n",
    "def list_splitter(list_to_split, ratio):\n",
    "    first_half = int(len(list_to_split) * ratio)\n",
    "    return list_to_split[:first_half], list_to_split[first_half:]\n",
    "\n",
    "def chunks(lst, n):\n",
    "    \"\"\"Yield successive n-sized chunks from lst.\"\"\"\n",
    "    for i in range(0, len(lst), n):\n",
    "        yield lst[i:i + n]\n",
    "\n",
    "dataSetFin = {\"test\": [], \"train\": [], \"valid\": []}\n",
    "data = []\n",
    "for category in list(set(categories)):\n",
    "    tracklets = []\n",
    "    for tracklet in dataSet['train']:\n",
    "        if tracklet['label'] == category:\n",
    "            subsequences = list(chunks(tracklet['paths'], 10))\n",
    "            # subsequences = [subsequence for subsequence in subsequences if len(subsequence) >= 5]\n",
    "            subsequences = [\n",
    "                {'paths': subsequence, 'label': category}\n",
    "                for subsequence in subsequences\n",
    "            ]\n",
    "            tracklets+=subsequences\n",
    "    data += tracklets\n",
    "\n",
    "labels = [tracklet['label'] for tracklet in  data]\n",
    "train, test, _, _ = train_test_split(data, labels, test_size=0.2, random_state=42)\n",
    "dataSetFin['train'] = train\n",
    "dataSetFin['test'] = test\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# Generate k folds validation set\n",
    "sKFold = StratifiedKFold(n_splits=3, random_state=None, shuffle=False)\n",
    "i = 0\n",
    "for train_index, test_index in sKFold.split(dataSetFin['train'], [tracklet['label'] for tracklet in  dataSetFin['train']]):\n",
    "    train, test = [], []\n",
    "    print(train_index[:10], test_index[:10])\n",
    "    for j in range(len(train_index)):\n",
    "        train.append(dataSetFin['train'][train_index[j]])\n",
    "    for j in range(len(test_index)):\n",
    "        test.append(dataSetFin['train'][test_index[j]])\n",
    "    dataSetFin['traink{}'.format(i)] = train\n",
    "    dataSetFin['testk{}'.format(i)] = test\n",
    "    i+=1\n",
    "\n",
    "import json\n",
    "# Save\n",
    "with open('./utils/opencowsTracklets2017.json', 'w') as fp:\n",
    "    json.dump(dataSetFin, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from utils.OpenSetCows2021 import OpenSetCows2021TrackLet\n",
    "import numpy\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import matplotlib.pyplot as plt\n",
    "from utils.classWeights import ClassWeights\n",
    "import math\n",
    "\n",
    "batchSize = 25\n",
    "trainingDataset = OpenSetCows2021TrackLet(\n",
    "    \"/Users/as16542/Downloads/10m32xl88x2b61zlkkgz3fml17\",\n",
    "    'utils/opencowsTracklets2020.json',\n",
    "    maxSequenceLength=5,\n",
    "    split='traink2',\n",
    "    trackletChoiceProb = 0.4,\n",
    "    eval=False,\n",
    "    batchSize=batchSize\n",
    ")\n",
    "\n",
    "trainingDataLoader = DataLoader(\n",
    "    trainingDataset, batch_size=batchSize, num_workers=2, shuffle=True\n",
    ")\n",
    "\n",
    "# fig = plt.figure()\n",
    "# ax = fig.add_axes([0,0,1,1])\n",
    "# distribution = numpy.asarray([[k, len(trainingDataset.lookup[k])] for k in trainingDataset.lookup.keys()])\n",
    "# langs = [str(i) for i in distribution[:,0]]\n",
    "# students = distribution[:,1] \n",
    "# ax.bar(langs,students)\n",
    "# plt.show()\n",
    "\n",
    "with open('utils/opencowsTracklets2020.json') as f:\n",
    "    dataSet = json.load(f)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "classFrequency = []\n",
    "for track in dataSet['train']:\n",
    "    classFrequency.append(track['label'])\n",
    "\n",
    "for track in dataSet['test']:\n",
    "    classFrequency.append(track['label'])\n",
    "\n",
    "print('ClassFrequency')\n",
    "fig = plt.figure()\n",
    "ax = fig.add_axes([0,0,1,1])\n",
    "langs = list(range(trainingDataset.numClasses))\n",
    "langs = [str(l) for l in langs]\n",
    "ax.bar(langs, trainingDataset.classFrequency)\n",
    "plt.show()\n",
    "\n",
    "print('SKlearn')\n",
    "fig = plt.figure()\n",
    "ax = fig.add_axes([0,0,1,1])\n",
    "weights = compute_class_weight(class_weight = 'balanced', classes = numpy.unique(classFrequency), y = classFrequency)\n",
    "\n",
    "# weights /= (numpy.sum(weights) * len(langs))\n",
    "ax.bar(langs, weights)\n",
    "plt.show()\n",
    "\n",
    "print('Effective Number of Samples')\n",
    "fig = plt.figure()\n",
    "ax = fig.add_axes([0,0,1,1])\n",
    "weights = ClassWeights(trainingDataset.classFrequency, trainingDataset.numClasses, 'ENS', beta=0.89, normalise=False)()\n",
    "ax.bar(langs, weights)\n",
    "plt.show()\n",
    "\n",
    "print('Inverse Number of Samples')\n",
    "fig = plt.figure()\n",
    "ax = fig.add_axes([0,0,1,1])\n",
    "weights = ClassWeights(trainingDataset.classFrequency, trainingDataset.numClasses, 'INS')()\n",
    "ax.bar(langs, weights)\n",
    "plt.show()\n",
    "\n",
    "print('Inverse Squareroot of Number of Samples')\n",
    "fig = plt.figure()\n",
    "ax = fig.add_axes([0,0,1,1])\n",
    "weights = ClassWeights(trainingDataset.classFrequency, trainingDataset.numClasses, 'ISNS')()\n",
    "ax.bar(langs, weights)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot([i%23 for i in range(92)])\n",
    "\n",
    "betaForENS = numpy.linspace(0.999, 0.92, 50)\n",
    "\n",
    "for i in range(len(betaForENS)):\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_axes([0,0,1,1])\n",
    "    ax.set_title(r\"$\\beta=${}, iteration: {}\".format(betaForENS[i], i))\n",
    "    weights = ClassWeights(trainingDataset.classFrequency, trainingDataset.numClasses, 'ENS', beta=betaForENS[i], normalise=False)() * 100\n",
    "    ax.bar(langs, weights)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAdwAAAE/CAYAAADsc3LZAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAWpklEQVR4nO3db4wc933f8fcnpCVHTg1L0VFlSLpUAtqNZMSSyxJO3QaJmVT0H4h6UAE06oBoVTAoVFcu0iZkDLTIAwJCW7jJgyoFYTsmascC49gR4aSuWSZuUKARQymyLUpiRFsOdSEjXhy4TmOADpVvH+yoXlF3uj3e7u929t4vgNiZ387cfb/7Zz47s3PDVBWSJGmyvmetC5AkaT0wcCVJasDAlSSpAQNXkqQGDFxJkhowcCVJamDjWhcAcPPNN9f27dvXugxJklbkscce+7Oqmhtl2akI3O3bt3P69Om1LkOSpBVJ8sejLushZUmSGjBwJUlqwMCVJKkBA1eSpAYMXEmSGjBwJUlqwMCVJKkBA1eSpAYMXEmSGjBwJUlqwMCVJKkBA1eSpAYMXEm6BtsP/hbbD/7WWpehHjFwJUnrwlp/SDJwJUlqwMCVJKmBZQM3yZuTPDH071tJPpjkpiQnkjzb3d44tM6hJOeSnE1y12RbkCRp+i0buFV1tqruqKo7gL8DfBv4LHAQOFlVO4CT3TxJbgP2AbcDe4CHkmyYTPn9tdbfJUjSNJrlbeNKDynvBr5aVX8M7AWOduNHgXu66b3Aw1V1uaqeA84Bu8ZQqyRJvbXSwN0HfKqbvqWqLgJ0t5u68S3A80PrzHdjL5PkQJLTSU4vLCyssAxJkvpl5MBNch1wN/Dryy26yFi9YqDqSFXtrKqdc3Nzo5YhSVIvrWQP913A41X1Qjf/QpLNAN3tpW58Htg2tN5W4MJqC5Ukqc9WErjv47uHkwGOA/u76f3AI0Pj+5Jcn+RWYAdwarWFSpLUZxtHWSjJDcBPAT8zNPwgcCzJfcB54F6AqjqT5BjwFHAFuL+qXhxr1WPy0plwX3/wPWtcyfTwMZGkyRgpcKvq28D3XzX2DQZnLS+2/GHg8KqrkyQtyw/K/eCVpjQ2s/z3c5K0WgauVsWQlTQJs7htMXAlaYa8WlDNYoj1yUjf4fbV8AvL7zbWht8tTQ+fC2ltuYfbQyv9lOqn2pVb7DGblcdxXH3MyuMhtWLgdlaz8ZjljbOk8ZvW7cO01vWSaa9vOTN9SHkWrOYwYJ9fmLPAQ7jSd/l+cA9XjfT9k+la8DGTZouBq7EzKCTpldblIeXVhIGHRSbPx3g2rNXz6OtnZWb98Zqm/tzDldRcq6MgHm3RNFmXe7jTahwnSE3DpzhpWKvXpsGqaece7hTyU/na8HHXNPB1OLtmcg/XF6t07TxaIk3GTAauJsMNsbRyvm/WxjTueBm4a8w349oa15vS57Gtlo+312R/db72R+d3uFeZ1u9PZunykX2t+yV9qL8PNUrrjXu465ifTGffLDzHs9DDNJqmD2Tr5TleN4E77id0vbxANHnjOmTpa3I00/Q4TVMtKzFtdU9bPUtZN4Grgb68MPtirfYS+voBcpoeL98Las3A1TWZpsNRi5nWjem01rWWfEwGpuk95XMyGQauppZveg1r/XqYxgAE/6vOl/Rx+2Dgaqb0fcPSx42IJqfvr2e9nIGrXujTd3CtN5LTtFGe1udkktZjz9Nq2p8L/w5Xi/LvOAXr73Uwrn5n6e/mRzXr/Y2De7hjNO2frtarWXpepmGDNg01rGez9HpebwzcV9HHF3Yfa14LhsbAuC9tud75OOjVeEi5IQ+5SNL65R6u9Co8YjDdfH6m09U7Fj4/AyPt4SZ5Q5JPJ3kmydNJfjTJTUlOJHm2u71xaPlDSc4lOZvkrsmVr/XGowTSaHyvTJ9R93B/Gfh8Vf2jJNcBNwC/AJysqgeTHAQOAj+f5DZgH3A78APA/0jypqp6cQL1S+7lSDNuVj44LLuHm+T1wI8BHwWoqu9U1TeBvcDRbrGjwD3d9F7g4aq6XFXPAeeAXeMtW5Lac69RqzHKHu4PAgvAryZ5K/AY8ABwS1VdBKiqi0k2dctvAX5/aP35buxlkhwADgC88Y1vvOYGJGm9Mvz7ZZTvcDcCbwN+paruBP6SweHjpWSRsXrFQNWRqtpZVTvn5uZGKnat+Kl2NvT1eexr3ZJebpQ93Hlgvqoe7eY/zSBwX0iyudu73QxcGlp+29D6W4EL4yq4b9xQahas1X8c4Pfys229bR+XDdyq+tMkzyd5c1WdBXYDT3X/9gMPdrePdKscB34tyYcZnDS1Azg1ieLVxiTfFOtlw7reNiySXmnUs5Q/AHyyO0P5a8A/YXA4+liS+4DzwL0AVXUmyTEGgXwFuN8zlCWpn9bLh+IWRgrcqnoC2LnIXbuXWP4wcPjay9J6sx7f1O71SuuLl3aUJ+VoKvg6nG4+P6tn4EqS1IDXUpa07rnnphbcw5UkNbOeD00buJIkNWDgSpLUgIErSVIDBq4kSQ0YuJIkNWDgSpLUgIErSVIDBq4kSQ0YuJIkNWDgSpLUgIErSVIDBq4kSQ0YuJIkNWDgSpLUgIErSVIDBq4kSQ0YuJIkNWDgSpLUgIErSVIDBq4kSQ0YuJIkNWDgSpLUgIErSVIDBq4kSQ0YuJIkNTBS4Cb5epKvJHkiyelu7KYkJ5I8293eOLT8oSTnkpxNctekipckqS9Wsof7E1V1R1Xt7OYPAieragdwspsnyW3APuB2YA/wUJINY6xZkqTeWc0h5b3A0W76KHDP0PjDVXW5qp4DzgG7VvF7JEnqvVEDt4AvJHksyYFu7JaqugjQ3W7qxrcAzw+tO9+NvUySA0lOJzm9sLBwbdVLktQTG0dc7h1VdSHJJuBEkmdeZdksMlavGKg6AhwB2Llz5yvulyRploy0h1tVF7rbS8BnGRwifiHJZoDu9lK3+DywbWj1rcCFcRUsSVIfLRu4SV6X5G+8NA38Q+BJ4Diwv1tsP/BIN30c2Jfk+iS3AjuAU+MuXJKkPhnlkPItwGeTvLT8r1XV55P8AXAsyX3AeeBegKo6k+QY8BRwBbi/ql6cSPWSJPXEsoFbVV8D3rrI+DeA3Uuscxg4vOrqJEmaEV5pSpKkBgxcSZIaMHAlSWrAwJUkqQEDV5KkBgxcSZIaMHAlSWrAwJUkqQEDV5KkBgxcSZIaMHAlSWrAwJUkqQEDV5KkBgxcSZIaMHAlSWrAwJUkqQEDV5KkBgxcSZIaMHAlSWrAwJUkqQEDV5KkBgxcSZIaMHAlSWrAwJUkqQEDV5KkBgxcSZIaMHAlSWrAwJUkqQEDV5KkBkYO3CQbkvxhks918zclOZHk2e72xqFlDyU5l+RskrsmUbgkSX2ykj3cB4Cnh+YPAieragdwspsnyW3APuB2YA/wUJIN4ylXkqR+Gilwk2wF3gN8ZGh4L3C0mz4K3DM0/nBVXa6q54BzwK6xVCtJUk+Nuof7S8DPAX89NHZLVV0E6G43deNbgOeHlpvvxl4myYEkp5OcXlhYWGndkiT1yrKBm+S9wKWqemzEn5lFxuoVA1VHqmpnVe2cm5sb8UdLktRPG0dY5h3A3UneDbwWeH2STwAvJNlcVReTbAYudcvPA9uG1t8KXBhn0ZIk9c2ye7hVdaiqtlbVdgYnQ/1OVb0fOA7s7xbbDzzSTR8H9iW5PsmtwA7g1NgrlySpR0bZw13Kg8CxJPcB54F7AarqTJJjwFPAFeD+qnpx1ZVKktRjKwrcqvoi8MVu+hvA7iWWOwwcXmVtkiTNDK80JUlSAwauJEkNGLiSJDVg4EqS1ICBK0lSAwauJEkNGLiSJDVg4EqS1ICBK0lSAwauJEkNGLiSJDVg4EqS1ICBK0lSAwauJEkNGLiSJDVg4EqS1ICBK0lSAwauJEkNGLiSJDVg4EqS1ICBK0lSAwauJEkNGLiSJDVg4EqS1ICBK0lSAwauJEkNGLiSJDVg4EqS1ICBK0lSA8sGbpLXJjmV5EtJziT5xW78piQnkjzb3d44tM6hJOeSnE1y1yQbkCSpD0bZw70MvLOq3grcAexJ8nbgIHCyqnYAJ7t5ktwG7ANuB/YADyXZMIHaJUnqjWUDtwb+bzf7mu5fAXuBo934UeCebnov8HBVXa6q54BzwK5xFi1JUt+M9B1ukg1JngAuASeq6lHglqq6CNDdbuoW3wI8P7T6fDcmSdK6NVLgVtWLVXUHsBXYleQtr7J4FvsRr1goOZDkdJLTCwsLIxUrSVJfregs5ar6JvBFBt/NvpBkM0B3e6lbbB7YNrTaVuDCIj/rSFXtrKqdc3NzK69ckqQeGeUs5bkkb+imvxf4SeAZ4Diwv1tsP/BIN30c2Jfk+iS3AjuAU2OuW5KkXtk4wjKbgaPdmcbfAxyrqs8l+d/AsST3AeeBewGq6kySY8BTwBXg/qp6cTLlS5LUD8sGblV9GbhzkfFvALuXWOcwcHjV1UmSNCO80pQkSQ0YuJIkNWDgSpLUgIErSVIDBq4kSQ0YuJIkNWDgSpLUgIErSVIDBq4kSQ0YuJIkNWDgSpLUgIErSVIDBq4kSQ0YuJIkNWDgSpLUgIErSVIDBq4kSQ0YuJIkNWDgSpLUgIErSVIDBq4kSQ0YuJIkNWDgSpLUgIErSVIDBq4kSQ0YuJIkNWDgSpLUgIErSVIDBq4kSQ0sG7hJtiX53SRPJzmT5IFu/KYkJ5I8293eOLTOoSTnkpxNctckG5AkqQ9G2cO9AvxsVf0w8Hbg/iS3AQeBk1W1AzjZzdPdtw+4HdgDPJRkwySKlySpL5YN3Kq6WFWPd9N/ATwNbAH2Ake7xY4C93TTe4GHq+pyVT0HnAN2jbluSZJ6ZUXf4SbZDtwJPArcUlUXYRDKwKZusS3A80OrzXdjkiStWyMHbpLvA34D+GBVfevVFl1krBb5eQeSnE5yemFhYdQyJEnqpZECN8lrGITtJ6vqM93wC0k2d/dvBi514/PAtqHVtwIXrv6ZVXWkqnZW1c65ublrrV+SpF4Y5SzlAB8Fnq6qDw/ddRzY303vBx4ZGt+X5PoktwI7gFPjK1mSpP7ZOMIy7wB+GvhKkie6sV8AHgSOJbkPOA/cC1BVZ5IcA55icIbz/VX14rgLlySpT5YN3Kr6Xyz+vSzA7iXWOQwcXkVdkiTNFK80JUlSAwauJEkNGLiSJDVg4EqS1ICBK0lSAwauJEkNGLiSJDVg4EqS1ICBK0lSAwauJEkNGLiSJDVg4EqS1ICBK0lSAwauJEkNGLiSJDVg4EqS1ICBK0lSAwauJEkNGLiSJDVg4EqS1ICBK0lSAwauJEkNGLiSJDVg4EqS1ICBK0lSAwauJEkNGLiSJDVg4EqS1ICBK0lSA8sGbpKPJbmU5MmhsZuSnEjybHd749B9h5KcS3I2yV2TKlySpD4ZZQ/348Ceq8YOAieragdwspsnyW3APuD2bp2HkmwYW7WSJPXUsoFbVb8H/PlVw3uBo930UeCeofGHq+pyVT0HnAN2jadUSZL661q/w72lqi4CdLebuvEtwPNDy813Y5IkrWvjPmkqi4zVogsmB5KcTnJ6YWFhzGVIkjRdrjVwX0iyGaC7vdSNzwPbhpbbClxY7AdU1ZGq2llVO+fm5q6xDEmS+uFaA/c4sL+b3g88MjS+L8n1SW4FdgCnVleiJEn9t3G5BZJ8Cvhx4OYk88C/Ax4EjiW5DzgP3AtQVWeSHAOeAq4A91fVixOqXZKk3lg2cKvqfUvctXuJ5Q8Dh1dTlCRJs8YrTUmS1ICBK0lSAwauJEkNGLiSJDVg4EqS1ICBK0lSAwauJEkNGLiSJDVg4EqS1ICBK0lSAwauJEkNGLiSJDVg4EqS1ICBK0lSAwauJEkNGLiSJDVg4EqS1ICBK0lSAwauJEkNGLiSJDVg4EqS1ICBK0lSAwauJEkNGLiSJDVg4EqS1ICBK0lSAwauJEkNGLiSJDVg4EqS1MDEAjfJniRnk5xLcnBSv0eSpD6YSOAm2QD8Z+BdwG3A+5LcNonfJUlSH0xqD3cXcK6qvlZV3wEeBvZO6HdJkjT1JhW4W4Dnh+bnuzFJktalVNX4f2hyL3BXVf2zbv6ngV1V9YGhZQ4AB7rZNwNnx1zGzcCfjflnrpVZ6WVW+gB7mVaz0sus9AGz38vfqqq5UVbeOP56gMEe7bah+a3AheEFquoIcGRCv58kp6tq56R+fkuz0sus9AH2Mq1mpZdZ6QPsZdikDin/AbAjya1JrgP2Accn9LskSZp6E9nDraorSf4F8N+BDcDHqurMJH6XJEl9MKlDylTVbwO/PamfP4KJHa5eA7PSy6z0AfYyrWall1npA+zl/5vISVOSJOnlvLSjJEkNzFzg9vmSkkm2JfndJE8nOZPkgW78piQnkjzb3d641rWOKsmGJH+Y5HPdfC97SfKGJJ9O8kz3/PxoH3tJ8q+619aTST6V5LV96SPJx5JcSvLk0NiStSc51G0Hzia5a22qXtwSvfyH7vX15SSfTfKGoft61cvQff86SSW5eWhsKntZqo8kH+hqPZPk3w+Nr7iPmQrcGbik5BXgZ6vqh4G3A/d39R8ETlbVDuBkN98XDwBPD833tZdfBj5fVX8beCuDnnrVS5ItwL8EdlbVWxic0LiP/vTxcWDPVWOL1t69b/YBt3frPNRtH6bFx3llLyeAt1TVjwB/BByC3vZCkm3ATwHnh8amuZePc1UfSX6CwVUSf6Sqbgf+Yzd+TX3MVODS80tKVtXFqnq8m/4LBhv1LQx6ONotdhS4Z00KXKEkW4H3AB8ZGu5dL0leD/wY8FGAqvpOVX2THvbC4ETJ702yEbiBwd/H96KPqvo94M+vGl6q9r3Aw1V1uaqeA84x2D5MhcV6qaovVNWVbvb3GVy/AHrYS+c/AT8HDJ8oNLW9LNHHPwcerKrL3TKXuvFr6mPWAndmLimZZDtwJ/AocEtVXYRBKAOb1rC0lfglBm+4vx4a62MvPwgsAL/aHR7/SJLX0bNequpPGHxCPw9cBP5PVX2BnvVxlaVq7/u24J8C/62b7l0vSe4G/qSqvnTVXX3r5U3AP0jyaJL/meTvduPX1MesBW4WGevdadhJvg/4DeCDVfWtta7nWiR5L3Cpqh5b61rGYCPwNuBXqupO4C+Z3sOuS+q+39wL3Ar8APC6JO9f26omprfbgiQfYvD10idfGlpksantJckNwIeAf7vY3YuMTW0vDN77NzL4iu/fAMeShGvsY9YCd9lLSk67JK9hELafrKrPdMMvJNnc3b8ZuLTU+lPkHcDdSb7O4ND+O5N8gn72Mg/MV9Wj3fynGQRw33r5SeC5qlqoqr8CPgP8PfrXx7Clau/ltiDJfuC9wD+u7/7NZt96+SEGH+q+1L3/twKPJ/mb9K+XeeAzNXCKwdG6m7nGPmYtcHt9Scnuk9NHgaer6sNDdx0H9nfT+4FHWte2UlV1qKq2VtV2Bs/D71TV++lnL38KPJ/kzd3QbuAp+tfLeeDtSW7oXmu7GZwn0Lc+hi1V+3FgX5Lrk9wK7ABOrUF9I0uyB/h54O6q+vbQXb3qpaq+UlWbqmp79/6fB97WvY961Qvwm8A7AZK8CbiOwX9ecG19VNVM/QPezeAMv68CH1rrelZY+99ncFjiy8AT3b93A9/P4AzMZ7vbm9a61hX29ePA57rpXvYC3AGc7p6b32RwmKl3vQC/CDwDPAn8V+D6vvQBfIrBd89/xWAjft+r1c7gsOZXGfxPZO9a6/pH6OUcg+8FX3rv/5e+9nLV/V8Hbp72XpZ4Tq4DPtG9Xx4H3rmaPrzSlCRJDczaIWVJkqaSgStJUgMGriRJDRi4kiQ1YOBKktSAgStJUgMGriRJDRi4kiQ18P8AXy62cefE6K8AAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pytorch_metric_learning.samplers import MPerClassSampler\n",
    "import matplotlib.pyplot as plt\n",
    "from utils.OpenSetCows2021 import OpenSetCows2021TrackLet\n",
    "from torch.utils.data.sampler import Sampler\n",
    "from pytorch_metric_learning.utils import common_functions as c_f\n",
    "import random\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy\n",
    "import torch\n",
    "from utils.classWeights import ClassWeights\n",
    "from copy import deepcopy\n",
    "\n",
    "class MPerClassTripletSampler(Sampler):\n",
    "    def __init__(\n",
    "        self, labels, m, batch_size=None, weights=None, length_before_new_iter=100000\n",
    "    ):\n",
    "        self.posSampler = MPerClassSampler(\n",
    "            labels,\n",
    "            m=m,\n",
    "            length_before_new_iter=length_before_new_iter,\n",
    "            batch_size=batch_size,\n",
    "        )\n",
    "        # Check if weights were supplied\n",
    "        if isinstance(weights, numpy.ndarray):\n",
    "            self.weights = torch.as_tensor(weights, dtype=torch.double)\n",
    "        else:\n",
    "            # Equal weights\n",
    "            self.weights = torch.ones(len(labels)) / len(labels)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.posSampler.list_size\n",
    "\n",
    "    def getSets(self):\n",
    "        # Suffle the labels twice to generate the positive and negative lists\n",
    "        c_f.NUMPY_RANDOM.shuffle(self.posSampler.labels)\n",
    "        curr_label_set, curr_label_set_neg = self.posSampler.labels, deepcopy(self.posSampler.labels)\n",
    "        c_f.NUMPY_RANDOM.shuffle(curr_label_set_neg)\n",
    "        return list(curr_label_set), list(curr_label_set_neg)\n",
    "\n",
    "    def __iter__(self):\n",
    "        idx_listPos, idx_listNeg = [0] * self.posSampler.list_size, [0] * self.posSampler.list_size\n",
    "        i = 0\n",
    "        num_iters = self.posSampler.calculate_num_iters()\n",
    "        for _ in range(num_iters):\n",
    "            curr_label_set, curr_label_set_neg = self.getSets()\n",
    "            if self.posSampler.batch_size is not None:\n",
    "                curr_label_set = self.posSampler.labels[\n",
    "                    : self.posSampler.batch_size // self.posSampler.m_per_class\n",
    "                ]\n",
    "\n",
    "            # Assign choice weights to anchors or positives\n",
    "            weightedIndeces = torch.multinomial(self.weights[curr_label_set], len(curr_label_set), True)\n",
    "            curr_label_set = [curr_label_set[index] for index in list(weightedIndeces.numpy())]\n",
    "            # Should we apply weights to the negatives as well? Not sure what effect that would have on the results\n",
    "            # weightedIndeces = torch.multinomial(self.weights[curr_label_set_neg], len(curr_label_set_neg), True)\n",
    "            # curr_label_set_neg = [curr_label_set_neg[index] for index in list(weightedIndeces.numpy())]\n",
    "\n",
    "            # Remove the anchors from the negative set\n",
    "            curr_label_set_neg = list(set(curr_label_set_neg) - set(curr_label_set))\n",
    "\n",
    "            for label in curr_label_set:\n",
    "                idx_listPos[\n",
    "                    i : i + self.posSampler.m_per_class\n",
    "                ] = c_f.safe_random_choice(self.posSampler.labels_to_indices[label], size=self.posSampler.m_per_class)\n",
    "\n",
    "                tex = random.choices(\n",
    "                    curr_label_set_neg,\n",
    "                    k=self.posSampler.m_per_class,\n",
    "                )\n",
    "                # Assert the the anchor does not appear in the negatives list\n",
    "                assert (idx_listPos[i] not in tex) == True\n",
    "                idx_listNeg[i : i + self.posSampler.m_per_class] = tex\n",
    "                i += self.posSampler.m_per_class\n",
    "        return iter(zip(idx_listPos, idx_listNeg))\n",
    "\n",
    "trainingDataset = OpenSetCows2021TrackLet(\n",
    "    \"/Users/as16542/Downloads/3owflku95bxsx24643cybxu3qh\",\n",
    "    \"./utils/opencowsTracklets2021.json\",\n",
    "    maxSequenceLength=5,\n",
    "    transform=None,    \n",
    "    trackletChoiceProb = 0.5,\n",
    "    eval=False,\n",
    "    batchSize=100\n",
    ")\n",
    "\n",
    "# Class weighted sampling\n",
    "# print(trainingDataset.numClasses, len(trainingDataset))\n",
    "sampler = MPerClassTripletSampler(\n",
    "    list(range(155)), m=3,\n",
    "    length_before_new_iter=1000,\n",
    "    batch_size=18,\n",
    "    weights=trainingDataset.getClassWeights('IMF')\n",
    ")\n",
    "# print(len(sampler.posSampler))\n",
    "distribuionPos = numpy.zeros(155)\n",
    "distribuionNeg = numpy.zeros(155)\n",
    "for i in range(100):\n",
    "  pos, neg = zip(*iter(sampler))\n",
    "  for classIdx in pos:\n",
    "    distribuionPos[classIdx] += 1\n",
    "  for classIdx in neg:\n",
    "      distribuionNeg[classIdx] += 1\n",
    "\n",
    "# distribuionPos /= len(sampler)\n",
    "# distribuionNeg /= len(sampler)\n",
    "# fig = plt.figure()\n",
    "# ax = fig.add_axes([0,0,1,1])\n",
    "# ax.bar(list(range(155)), trainingDataset.classFrequency)\n",
    "# plt.show()\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_axes([0,0,1,1])\n",
    "ax.bar(list(range(155)), distribuionPos)\n",
    "plt.show()\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_axes([0,0,1,1])\n",
    "ax.bar(list(range(155)), distribuionNeg)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x1124a3550>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/metricLearning/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1358, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/metricLearning/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1322, in _shutdown_workers\n",
      "    w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/metricLearning/lib/python3.8/multiprocessing/process.py\", line 149, in join\n",
      "    res = self._popen.wait(timeout)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/metricLearning/lib/python3.8/multiprocessing/popen_fork.py\", line 44, in wait\n",
      "    if not wait([self.sentinel], timeout):\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/metricLearning/lib/python3.8/multiprocessing/connection.py\", line 931, in wait\n",
      "    ready = selector.select(timeout)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/metricLearning/lib/python3.8/selectors.py\", line 415, in select\n",
      "    fd_event_list = self._selector.poll(timeout)\n",
      "KeyboardInterrupt: \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [26]\u001b[0m, in \u001b[0;36m<cell line: 30>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     29\u001b[0m distribuionNegative \u001b[39m=\u001b[39m numpy\u001b[39m.\u001b[39mzeros(\u001b[39m23\u001b[39m)\n\u001b[1;32m     30\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m100\u001b[39m):\n\u001b[0;32m---> 31\u001b[0m     _, _, _,  positiveLabel, negativeLabel \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39;49m(\u001b[39miter\u001b[39;49m(trainingDataLoader))\n\u001b[1;32m     32\u001b[0m     \u001b[39mfor\u001b[39;00m classIdx \u001b[39min\u001b[39;00m positiveLabel:\n\u001b[1;32m     33\u001b[0m         distribuionPositive[classIdx] \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/metricLearning/lib/python3.8/site-packages/torch/utils/data/dataloader.py:530\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/metricLearning/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=527'>528</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/metricLearning/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=528'>529</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()\n\u001b[0;32m--> <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/metricLearning/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=529'>530</a>\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[1;32m    <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/metricLearning/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=530'>531</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/metricLearning/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=531'>532</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/metricLearning/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=532'>533</a>\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/metricLearning/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=533'>534</a>\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/metricLearning/lib/python3.8/site-packages/torch/utils/data/dataloader.py:1207\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/metricLearning/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=1203'>1204</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_process_data(data)\n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/metricLearning/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=1205'>1206</a>\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_shutdown \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_tasks_outstanding \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m-> <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/metricLearning/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=1206'>1207</a>\u001b[0m idx, data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_data()\n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/metricLearning/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=1207'>1208</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_tasks_outstanding \u001b[39m-\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/metricLearning/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=1208'>1209</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable:\n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/metricLearning/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=1209'>1210</a>\u001b[0m     \u001b[39m# Check for _IterableDatasetStopIteration\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/metricLearning/lib/python3.8/site-packages/torch/utils/data/dataloader.py:1173\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/metricLearning/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=1168'>1169</a>\u001b[0m     \u001b[39m# In this case, `self._data_queue` is a `queue.Queue`,. But we don't\u001b[39;00m\n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/metricLearning/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=1169'>1170</a>\u001b[0m     \u001b[39m# need to call `.task_done()` because we don't use `.join()`.\u001b[39;00m\n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/metricLearning/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=1170'>1171</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/metricLearning/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=1171'>1172</a>\u001b[0m     \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m-> <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/metricLearning/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=1172'>1173</a>\u001b[0m         success, data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_try_get_data()\n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/metricLearning/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=1173'>1174</a>\u001b[0m         \u001b[39mif\u001b[39;00m success:\n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/metricLearning/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=1174'>1175</a>\u001b[0m             \u001b[39mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/metricLearning/lib/python3.8/site-packages/torch/utils/data/dataloader.py:1011\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/metricLearning/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=997'>998</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_try_get_data\u001b[39m(\u001b[39mself\u001b[39m, timeout\u001b[39m=\u001b[39m_utils\u001b[39m.\u001b[39mMP_STATUS_CHECK_INTERVAL):\n\u001b[1;32m    <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/metricLearning/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=998'>999</a>\u001b[0m     \u001b[39m# Tries to fetch data from `self._data_queue` once for a given timeout.\u001b[39;00m\n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/metricLearning/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=999'>1000</a>\u001b[0m     \u001b[39m# This can also be used as inner loop of fetching without timeout, with\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/metricLearning/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=1007'>1008</a>\u001b[0m     \u001b[39m# Returns a 2-tuple:\u001b[39;00m\n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/metricLearning/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=1008'>1009</a>\u001b[0m     \u001b[39m#   (bool: whether successfully get data, any: data if successful else None)\u001b[39;00m\n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/metricLearning/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=1009'>1010</a>\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/metricLearning/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=1010'>1011</a>\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_data_queue\u001b[39m.\u001b[39;49mget(timeout\u001b[39m=\u001b[39;49mtimeout)\n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/metricLearning/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=1011'>1012</a>\u001b[0m         \u001b[39mreturn\u001b[39;00m (\u001b[39mTrue\u001b[39;00m, data)\n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/metricLearning/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=1012'>1013</a>\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/metricLearning/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=1013'>1014</a>\u001b[0m         \u001b[39m# At timeout and error, we manually check whether any worker has\u001b[39;00m\n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/metricLearning/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=1014'>1015</a>\u001b[0m         \u001b[39m# failed. Note that this is the only mechanism for Windows to detect\u001b[39;00m\n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/metricLearning/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=1015'>1016</a>\u001b[0m         \u001b[39m# worker failures.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/metricLearning/lib/python3.8/multiprocessing/queues.py:107\u001b[0m, in \u001b[0;36mQueue.get\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/metricLearning/lib/python3.8/multiprocessing/queues.py?line=104'>105</a>\u001b[0m \u001b[39mif\u001b[39;00m block:\n\u001b[1;32m    <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/metricLearning/lib/python3.8/multiprocessing/queues.py?line=105'>106</a>\u001b[0m     timeout \u001b[39m=\u001b[39m deadline \u001b[39m-\u001b[39m time\u001b[39m.\u001b[39mmonotonic()\n\u001b[0;32m--> <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/metricLearning/lib/python3.8/multiprocessing/queues.py?line=106'>107</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_poll(timeout):\n\u001b[1;32m    <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/metricLearning/lib/python3.8/multiprocessing/queues.py?line=107'>108</a>\u001b[0m         \u001b[39mraise\u001b[39;00m Empty\n\u001b[1;32m    <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/metricLearning/lib/python3.8/multiprocessing/queues.py?line=108'>109</a>\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_poll():\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/metricLearning/lib/python3.8/multiprocessing/connection.py:257\u001b[0m, in \u001b[0;36m_ConnectionBase.poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/metricLearning/lib/python3.8/multiprocessing/connection.py?line=254'>255</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_closed()\n\u001b[1;32m    <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/metricLearning/lib/python3.8/multiprocessing/connection.py?line=255'>256</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_readable()\n\u001b[0;32m--> <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/metricLearning/lib/python3.8/multiprocessing/connection.py?line=256'>257</a>\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_poll(timeout)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/metricLearning/lib/python3.8/multiprocessing/connection.py:424\u001b[0m, in \u001b[0;36mConnection._poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/metricLearning/lib/python3.8/multiprocessing/connection.py?line=422'>423</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_poll\u001b[39m(\u001b[39mself\u001b[39m, timeout):\n\u001b[0;32m--> <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/metricLearning/lib/python3.8/multiprocessing/connection.py?line=423'>424</a>\u001b[0m     r \u001b[39m=\u001b[39m wait([\u001b[39mself\u001b[39;49m], timeout)\n\u001b[1;32m    <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/metricLearning/lib/python3.8/multiprocessing/connection.py?line=424'>425</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mbool\u001b[39m(r)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/metricLearning/lib/python3.8/multiprocessing/connection.py:931\u001b[0m, in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m    <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/metricLearning/lib/python3.8/multiprocessing/connection.py?line=927'>928</a>\u001b[0m     deadline \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mmonotonic() \u001b[39m+\u001b[39m timeout\n\u001b[1;32m    <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/metricLearning/lib/python3.8/multiprocessing/connection.py?line=929'>930</a>\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m--> <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/metricLearning/lib/python3.8/multiprocessing/connection.py?line=930'>931</a>\u001b[0m     ready \u001b[39m=\u001b[39m selector\u001b[39m.\u001b[39;49mselect(timeout)\n\u001b[1;32m    <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/metricLearning/lib/python3.8/multiprocessing/connection.py?line=931'>932</a>\u001b[0m     \u001b[39mif\u001b[39;00m ready:\n\u001b[1;32m    <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/metricLearning/lib/python3.8/multiprocessing/connection.py?line=932'>933</a>\u001b[0m         \u001b[39mreturn\u001b[39;00m [key\u001b[39m.\u001b[39mfileobj \u001b[39mfor\u001b[39;00m (key, events) \u001b[39min\u001b[39;00m ready]\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/metricLearning/lib/python3.8/selectors.py:415\u001b[0m, in \u001b[0;36m_PollLikeSelector.select\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/metricLearning/lib/python3.8/selectors.py?line=412'>413</a>\u001b[0m ready \u001b[39m=\u001b[39m []\n\u001b[1;32m    <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/metricLearning/lib/python3.8/selectors.py?line=413'>414</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/metricLearning/lib/python3.8/selectors.py?line=414'>415</a>\u001b[0m     fd_event_list \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_selector\u001b[39m.\u001b[39;49mpoll(timeout)\n\u001b[1;32m    <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/metricLearning/lib/python3.8/selectors.py?line=415'>416</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mInterruptedError\u001b[39;00m:\n\u001b[1;32m    <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/metricLearning/lib/python3.8/selectors.py?line=416'>417</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m ready\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from pytorch_metric_learning.samplers import MPerClassSampler\n",
    "import matplotlib.pyplot as plt\n",
    "from utils.OpenSetCows2021 import OpenSetCows2021TrackLet\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy\n",
    "from random import choices\n",
    "\n",
    "trainingDataset = OpenSetCows2021TrackLet(\n",
    "    \"/Users/as16542/Downloads/3owflku95bxsx24643cybxu3qh\",\n",
    "    \"./utils/opencowsTracklets2017.json\",\n",
    "    maxSequenceLength=5,\n",
    "    transform=None,    \n",
    "    trackletChoiceProb = 0.5,\n",
    "    eval=False,\n",
    "    batchSize=100\n",
    ")\n",
    "\n",
    "sampler = MPerClassTripletSampler(\n",
    "    list(range(23)), m=5, length_before_new_iter=len(trainingDataset),\n",
    "    batch_size=100\n",
    ")\n",
    "\n",
    "\n",
    "trainingDataLoader = DataLoader(\n",
    "    trainingDataset, batch_size=100, num_workers=1, shuffle=False, pin_memory=True, sampler=sampler\n",
    ")\n",
    "\n",
    "distribuionPositive = numpy.zeros(23)\n",
    "distribuionNegative = numpy.zeros(23)\n",
    "for i in range(100):\n",
    "    _, _, _,  positiveLabel, negativeLabel = next(iter(trainingDataLoader))\n",
    "    for classIdx in positiveLabel:\n",
    "        distribuionPositive[classIdx] += 1\n",
    "\n",
    "    for classIdx in negativeLabel:\n",
    "        distribuionNegative[classIdx] += 1  \n",
    "\n",
    "distribuionNegative /= 100\n",
    "distribuionPositive /= 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = (15, 5)\n",
    "# plot data in grouped manner of bar type\n",
    "print('Positive Sampling')\n",
    "width = 0.40\n",
    "x = numpy.array(range(23))\n",
    "ax = plt.axes()\n",
    "\n",
    "plt.bar(x-0.2, distribuionPositive, width, color='cyan')\n",
    "plt.bar(x+0.2, distribuionNegative, width, color='green')\n",
    "\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(['$C_{{{}}}$'.format(i) for i in range(23)])\n",
    "\n",
    "plt.xlabel(\"Individual\")\n",
    "plt.ylabel(\"Number of Samples\")\n",
    "plt.legend([\"Positive\", \"Negative\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "positiveLabel\n",
    "weights = compute_class_weight(class_weight = 'balanced', classes = numpy.unique(classFrequency), y = classFrequency)\n",
    "population = list(range(23))\n",
    "\n",
    "negSamples = []\n",
    "for label in positiveLabel:\n",
    "    w, p = list(weights), \n",
    "    w.pop(label)\n",
    "    p.pop(label)\n",
    "    negSamples.append(choices(p, w)[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(range(23)).pop(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = 28\n",
    "cols = 28\n",
    "label = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
    "sprite_dim = int(np.sqrt(x_test.shape[0]))\n",
    "sprite_image = np.ones((cols sprite_dim, rows sprite_dim))\n",
    "index = 0\n",
    "labels = []\n",
    "for i in range(sprite_dim):\n",
    "  for j in range(sprite_dim):\n",
    "    labels.append(label[int(y_test[index])])\n",
    "\n",
    "    sprite_image[\n",
    "        i * cols: (i + 1) * cols,\n",
    "        j * rows: (j + 1) * rows\n",
    "    ] = x_test[index].reshape(28, 28) * -1 + 1\n",
    "\n",
    "    index += 1"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a35bd2a748ff812196078b530039d66aaa336851f47ca82b0a06ab1bf96aa2d4"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('metricLearning': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
