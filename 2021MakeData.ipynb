{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "import glob\n",
    "import numpy\n",
    "from PIL import ImageDraw \n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import ImageFont\n",
    "\n",
    "def loadResizeImage(img_path, label=None):\n",
    "    size = (124, 124)\n",
    "\n",
    "    # Load the image\n",
    "    img = Image.open(img_path)\n",
    "    # Keep the original image size\n",
    "    old_size = img.size\n",
    "\n",
    "    # Compute resizing ratio\n",
    "    ratio = float(size[0]) / max(old_size)\n",
    "    new_size = tuple([int(x * ratio) for x in old_size])\n",
    "\n",
    "    # Actually resize it\n",
    "    img = img.resize(new_size, Image.ANTIALIAS)\n",
    "\n",
    "    # Paste into centre of black padded image\n",
    "    new_img = Image.new(\"RGB\", (size[0], size[1]))\n",
    "    new_img.paste(img, ((size[0] - new_size[0]) // 2, (size[1] - new_size[1]) // 2))\n",
    "    if label != None:\n",
    "        draw = ImageDraw.Draw(new_img)\n",
    "        font = ImageFont.truetype(\"/System/Library/Fonts/Supplemental/Arial.ttf\", 12)\n",
    "        draw.text((62, 10),label,(255,255,255),font=font)\n",
    "\n",
    "    # Convert to numpy\n",
    "    new_img = numpy.array(new_img, dtype=numpy.uint8)\n",
    "\n",
    "    return new_img\n",
    "\n",
    "# Function to compose images in a grid\n",
    "compose = lambda images, horizontal: numpy.concatenate(\n",
    "    [img / 255 if horizontal == 1 else img for img in images],\n",
    "    axis=horizontal,\n",
    ")\n",
    "\n",
    "def listDirs(dir):\n",
    "    images = glob.glob(dir + '/*')\n",
    "    timestamps = [os.path.getctime(path) for path in images]\n",
    "    indeces = numpy.argsort(timestamps)\n",
    "    images = [images[idx] for idx in indeces]\n",
    "    return images, indeces\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip3 install xlsxwriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import xlsxwriter\n",
    "# import cv2\n",
    "# from io import BytesIO\n",
    "# # This sorts images based on timestamps. These are used to manually annotate the dataset.\n",
    "# topDir = '/Users/as16542/Downloads/10m32xl88x2b61zlkkgz3fml17/identification/images/test/*'\n",
    "# dirs = glob.glob(topDir)\n",
    "# for dir in dirs:\n",
    "#     img, indeces = listDirs(dir)\n",
    "#     # Create an new Excel file and add a worksheet.\n",
    "#     workbook = xlsxwriter.Workbook('./tracklets/{}.xlsx'.format(dir.split('/')[-1]))\n",
    "#     worksheet = workbook.add_worksheet()\n",
    "#     sheetFormat = workbook.add_format({'text_wrap': True})\n",
    "#     # Widen the first column to make the text clearer.\n",
    "#     worksheet.set_column('A:A', 30, sheetFormat)\n",
    "#     worksheet.set_column('B:B', 17)\n",
    "#     for i in range(len(img)):\n",
    "#         # Insert an image.\n",
    "#         worksheet.set_row(i, 92)\n",
    "#         success, img_numpy = cv2.imencode('.jpg', loadResizeImage(img[i], label=str(i)))\n",
    "#         worksheet.write('A{}'.format(i), img[i])\n",
    "#         worksheet.insert_image('B{}'.format(i), img[i], {'image_data': BytesIO(img_numpy.tobytes())})\n",
    "#     workbook.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# topDir = '/Users/as16542/Downloads/10m32xl88x2b61zlkkgz3fml17/identification/images/test/*'\n",
    "# dirs = glob.glob(topDir)\n",
    "# for dir in dirs:\n",
    "#     img, indeces = listDirs(dir)\n",
    "#     fig, ax = plt.subplots(1, figsize=((len(img) * 124)/500, 124/500), dpi=500)\n",
    "#     img = [loadResizeImage(img[i], label=str(i)) for i in range(len(img))]\n",
    "#     plt.imshow(compose(img, 1), aspect=1)\n",
    "#     [ax.spines[spine].set_visible(False) for spine in [\"top\", \"right\", \"bottom\", \"left\"]]\n",
    "#     ax.axes.get_xaxis().set_ticks([])\n",
    "#     ax.axes.get_yaxis().set_ticks([])\n",
    "#     ax.axis(\"tight\")\n",
    "#     # print(\"{} {}\".format(dir, len(img)))\n",
    "#     plt.savefig(\"./tracklets/{}.png\".format(dir.split('/')[-1]), dpi=500)\n",
    "#     plt.figure().clear()\n",
    "#     plt.close()\n",
    "#     plt.cla()\n",
    "#     plt.clf()\n",
    "#     # break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Open cows 2020 tracklets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import csv\n",
    "import numpy\n",
    "import json\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "# !pip3 install imblearn\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "def listDirs(dir):\n",
    "    images = glob.glob(dir + '/*')\n",
    "    timestamps = [os.path.getctime(path) for path in images]\n",
    "    indeces = numpy.argsort(timestamps)\n",
    "    images = [images[idx] for idx in indeces]\n",
    "    return images, indeces\n",
    "\n",
    "def chunks(lst, n):\n",
    "    \"\"\"Yield successive n-sized chunks from lst.\"\"\"\n",
    "    for i in range(0, len(lst), n):\n",
    "        yield lst[i:i + n]\n",
    "\n",
    "topDir = './tracklets/train/csv/*'\n",
    "dirs = glob.glob(topDir)\n",
    "dataSet = {\"test\": [], \"train\": [], \"valid\": []}\n",
    "ignoreIndex = 1000\n",
    "for dir in dirs:\n",
    "    # Parse the train data\n",
    "    with open(dir) as csv_file:\n",
    "        csv_reader = csv.reader(csv_file, delimiter=',')\n",
    "        data = []\n",
    "        trackletInd = []\n",
    "        for row in csv_reader:\n",
    "            row[0] = row[0].replace('/Users/as16542/Downloads/10m32xl88x2b61zlkkgz3fml17/', '')\n",
    "            category = int(row[0].split('/')[-2])\n",
    "            if category < ignoreIndex:\n",
    "                data.append([row[0], category, int(row[1])])\n",
    "                trackletInd.append(int(row[1]))\n",
    "\n",
    "        dataRow = []\n",
    "        for i in range(len(numpy.unique(trackletInd))):\n",
    "            dataRow += [{'paths':[], 'label': ''}]\n",
    "        for path, category, tracklet in data:\n",
    "            dataRow[tracklet]['label'] = category\n",
    "            dataRow[tracklet]['paths'].append(path)\n",
    "        dataSet['train'] += dataRow\n",
    "\n",
    "# Append data from the test set file\n",
    "topDIR = '/Users/as16542/Downloads/10m32xl88x2b61zlkkgz3fml17/identification/images/test/'\n",
    "with open('utils/openCows2020_test_tracklet.json') as f:\n",
    "    files = json.load(f)\n",
    "    for file in files:\n",
    "        if file['type'] == 'split':\n",
    "            directories, indeces = listDirs(topDIR + file['cowID'])\n",
    "            for split in file['splits']:\n",
    "                if int(file['cowID']) < ignoreIndex:\n",
    "                    sortedIdx = [directories[idx].replace('/Users/as16542/Downloads/10m32xl88x2b61zlkkgz3fml17/', '') for idx in split]\n",
    "                    dataSet['train'].append({\"label\": int(file['cowID']), \"paths\": sortedIdx})\n",
    "        else:\n",
    "            if int(file['cowID']) < ignoreIndex:\n",
    "                directories, indeces = listDirs(topDIR + file['cowID'])\n",
    "                directories = [director.replace('/Users/as16542/Downloads/10m32xl88x2b61zlkkgz3fml17/', '') for director in directories]\n",
    "                dataSet['train'].append({\"label\": int(file['cowID']), \"paths\": directories})\n",
    "\n",
    "# Lets devide the sequences into smaller sequences of length 5\n",
    "data = []\n",
    "for tracklet in dataSet['train']:\n",
    "    label = tracklet['label'] - 1\n",
    "    subsequences = list(chunks(tracklet['paths'], 5))\n",
    "    sequences = []\n",
    "    for sequence in subsequences:\n",
    "        sequence = {'paths': sequence, 'label': label}\n",
    "        sequences.append(sequence)\n",
    "    data += sequences\n",
    "\n",
    "labels = [tracklet['label'] for tracklet in  data]\n",
    "# Now let make the test and train split\n",
    "train, test, _, _ = train_test_split(data, labels, test_size=0.3, random_state=42, stratify=labels)\n",
    "dataSetFin = {\"test\": test, \"train\": train, \"valid\": []}\n",
    "\n",
    "# Generate k folds validation set\n",
    "sKFold = StratifiedKFold(n_splits=3, random_state=42, shuffle=True)\n",
    "i = 0\n",
    "for train_index, test_index in sKFold.split(dataSetFin['train'], [tracklet['label'] for tracklet in  dataSetFin['train']]):\n",
    "    train, test = [], []\n",
    "    for j in range(len(train_index)):\n",
    "        train.append(dataSetFin['train'][train_index[j]])\n",
    "    for j in range(len(test_index)):\n",
    "        test.append(dataSetFin['train'][test_index[j]])\n",
    "\n",
    "    dataSetFin['traink{}'.format(i)] = train\n",
    "    dataSetFin['testk{}'.format(i)] = test\n",
    "    i+=1\n",
    "\n",
    "import json\n",
    "# Save\n",
    "with open('./utils/opencowsTracklets2020.json', 'w') as fp:\n",
    "    json.dump(dataSetFin, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "classFrequency = numpy.zeros(numpy.unique(labels).shape)\n",
    "\n",
    "def labels_to_class_weights(labels, nc=80): \n",
    "    # Get class weights (inverse frequency) from training labels \n",
    "    classes = numpy.asarray(labels)\n",
    "    weights = numpy.bincount(classes, minlength=nc)  # occurences per class \n",
    "    weights[weights == 0] = 1  # replace empty bins with 1 \n",
    "    weights = 1 / weights  # number of targets per class \n",
    "    weights /= weights.sum()  # normalize \n",
    "    return weights\n",
    "\n",
    "for track in dataSetFin['traink0']:\n",
    "    classFrequency[track['label']] += 1\n",
    "\n",
    "# for track in data:\n",
    "#     classFrequency[track['label']] += 1\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (15, 5)\n",
    "width = 0.40\n",
    "x = numpy.unique(labels)\n",
    "ax = plt.axes()\n",
    "# plt.bar(x-0.2, classFrequency, width, color='cyan')\n",
    "plt.bar(x-0.2, classFrequency / numpy.sum(classFrequency), width, color='cyan')\n",
    "plt.bar(x+0.2, labels_to_class_weights(labels, nc=len(x)), width, color='green')\n",
    "\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(['$C_{{{}}}$'.format(i) for i in x])\n",
    "plt.xlabel(\"Individual\")\n",
    "plt.ylabel(\"Number of Samples\")\n",
    "plt.legend([\"Class frequency\", \"Weights\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "topDIR = '/Users/as16542/Downloads/10m32xl88x2b61zlkkgz3fml17/identification/images/train/'\n",
    "dataSet = {\"test\": [], \"train\": [], \"valid\": []}\n",
    "with open('utils/openCows2020_train_tracklet.json') as f:\n",
    "    files = json.load(f)\n",
    "    for file in files:\n",
    "        if file['type'] == 'split':\n",
    "            directories, indeces = listDirs(topDIR + file['cowID'])\n",
    "            for split in file['splits']:\n",
    "                sortedIdx = [directories[idx].replace('/Users/as16542/Downloads/10m32xl88x2b61zlkkgz3fml17/', '') for idx in split]\n",
    "                dataSet['train'].append({\"label\": int(file['cowID']), \"paths\": sortedIdx})\n",
    "        else:\n",
    "            directories, indeces = listDirs(topDIR + file['cowID'])\n",
    "            directories = [director.replace('/Users/as16542/Downloads/10m32xl88x2b61zlkkgz3fml17/', '') for director in directories]\n",
    "            dataSet['train'].append({\"label\": int(file['cowID']), \"paths\": directories})\n",
    "\n",
    "topDIR = '/Users/as16542/Downloads/10m32xl88x2b61zlkkgz3fml17/identification/images/test/'\n",
    "with open('utils/openCows2020_test_tracklet.json') as f:\n",
    "    files = json.load(f)\n",
    "    for file in files:\n",
    "        if file['type'] == 'split':\n",
    "            directories, indeces = listDirs(topDIR + file['cowID'])\n",
    "            for split in file['splits']:\n",
    "                sortedIdx = [directories[idx].replace('/Users/as16542/Downloads/10m32xl88x2b61zlkkgz3fml17/', '') for idx in split]\n",
    "                dataSet['test'].append({\"label\": int(file['cowID']), \"paths\": sortedIdx})\n",
    "        else:\n",
    "            directories, indeces = listDirs(topDIR + file['cowID'])\n",
    "            directories = [director.replace('/Users/as16542/Downloads/10m32xl88x2b61zlkkgz3fml17/', '') for director in directories]\n",
    "            dataSet['test'].append({\"label\": int(file['cowID']), \"paths\": directories})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = [len(track['paths']) for track in dataSet['test']]\n",
    "plt.plot(dt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2021 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "import glob\n",
    "import numpy\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def chunks(lst, n):\n",
    "    \"\"\"Yield successive n-sized chunks from lst.\"\"\"\n",
    "    for i in range(0, len(lst), n):\n",
    "        yield lst[i:i + n]\n",
    "\n",
    "def listDirs(dir):\n",
    "    images = glob.glob(dir + '/*')\n",
    "    timestamps = [os.path.getctime(path) for path in images]\n",
    "    indeces = numpy.argsort(timestamps)\n",
    "    images = [images[idx] for idx in indeces]\n",
    "    return images\n",
    "\n",
    "topDir = '/Users/as16542/Downloads/4vnrca7qw1642qlwxjadp87h7/Sub-levels/Identification/Train/RGBDCows2020/Identification/RGB'\n",
    "dataSet = {\"test\": [], \"train\": [], \"valid\": []}\n",
    "\n",
    "# Parse the train data\n",
    "with open('utils/correct.csv') as csv_file:\n",
    "    csv_reader = csv.reader(csv_file, delimiter=',')\n",
    "    line_count = 0\n",
    "    for row in csv_reader:\n",
    "        if line_count > 0 and line_count < 465 and row[6] != 'black':\n",
    "            label = row[4] if row[4] != '' else row[2]\n",
    "            if label != '':\n",
    "                dirs = [dir.replace('/Users/as16542/Downloads/4vnrca7qw1642qlwxjadp87h7/', '') for dir in listDirs(os.path.join(topDir, row[1]))]\n",
    "                # Split into smaller sequences\n",
    "                subsequences = list(chunks(dirs, 10))\n",
    "                subsequences = [\n",
    "                    {'paths': subsequence, 'label': int(label)}\n",
    "                    for subsequence in subsequences\n",
    "                ]\n",
    "                dataSet['train'] += subsequences\n",
    "        line_count += 1\n",
    "\n",
    "# Parse the test data\n",
    "labels = list(set([item['label'] for item in dataSet[\"train\"]]))\n",
    "topDir = '/Users/as16542/Downloads/4vnrca7qw1642qlwxjadp87h7/Sub-levels/Identification/Test/'\n",
    "for label in labels:\n",
    "    path = os.path.join(topDir, '{:>03}'.format(label))\n",
    "    dirs = [dir.replace('/Users/as16542/Downloads/4vnrca7qw1642qlwxjadp87h7/', '') for dir in listDirs(path)]\n",
    "    # Split into smaller sequences\n",
    "    subsequences = list(chunks(dirs, 10))\n",
    "    subsequences = [\n",
    "        {'paths': subsequence, 'label': int(label)}\n",
    "        for subsequence in subsequences\n",
    "    ]\n",
    "    dataSet['test'] += subsequences    \n",
    "    # dataSet[\"test\"].append({'label': int(label), 'paths': dirs})\n",
    "\n",
    "# Since we omitted black cows we need to remove some classes and reindex the labels again\n",
    "labels = list(set([item['label'] for item in dataSet[\"train\"]] + [item['label'] for item in dataSet[\"test\"]]))\n",
    "hotEncodeMap = {}\n",
    "for i in range(len(labels)):\n",
    "    hotEncodeMap[labels[i]] = i\n",
    "\n",
    "# Now we can use the map the relabel the dataset\n",
    "for split in dataSet.keys():\n",
    "    for i in range(len(dataSet[split])):\n",
    "        dataSet[split][i]['label'] = hotEncodeMap[dataSet[split][i]['label']]\n",
    "\n",
    "# Prepare for k-fold splits\n",
    "data = dataSet['train'] + dataSet['test']\n",
    "labels = [item['label'] for item in data]\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# Generate k folds validation set\n",
    "sKFold = StratifiedKFold(n_splits=3, random_state=None, shuffle=False)\n",
    "dataSetFin = {\"test\": [], \"train\": [], \"valid\": []}\n",
    "i = 0\n",
    "for train_index, test_index in sKFold.split(data, labels):\n",
    "    train, test = [], []\n",
    "    for j in range(len(train_index)):\n",
    "        train.append(data[train_index[j]])\n",
    "    for j in range(len(test_index)):\n",
    "        test.append(data[test_index[j]])\n",
    "    dataSetFin['traink{}'.format(i)] = train\n",
    "    dataSetFin['testk{}'.format(i)] = test\n",
    "    i+=1\n",
    "\n",
    "# Now let make the test and train split\n",
    "train, test, _, _ = train_test_split(data, labels, test_size=0.3, random_state=42, stratify=labels)\n",
    "dataSetFin['train'] = train\n",
    "dataSetFin['test'] = test\n",
    "\n",
    "import json\n",
    "# Save\n",
    "with open('./utils/opencowsTracklets2021.json', 'w') as fp:\n",
    "    json.dump(dataSetFin, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "classFrequency = numpy.zeros(numpy.unique(labels).shape)\n",
    "\n",
    "def labels_to_class_weights(labels, nc=80): \n",
    "    # Get class weights (inverse frequency) from training labels \n",
    "    classes = numpy.asarray(labels)\n",
    "    weights = numpy.bincount(classes, minlength=nc)  # occurences per class \n",
    "    weights[weights == 0] = 1  # replace empty bins with 1 \n",
    "    weights = 1 / weights  # number of targets per class \n",
    "    weights /= weights.sum()  # normalize \n",
    "    return weights\n",
    "\n",
    "for track in dataSetFin['traink0']:\n",
    "    classFrequency[track['label']] += 1\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (15, 5)\n",
    "width = 0.40\n",
    "x = numpy.unique(labels)\n",
    "ax = plt.axes()\n",
    "# plt.bar(x-0.2, classFrequency, width, color='cyan')\n",
    "plt.bar(x-0.2, classFrequency / numpy.sum(classFrequency), width, color='cyan')\n",
    "plt.bar(x+0.2, labels_to_class_weights(labels, nc=len(x)), width, color='green')\n",
    "\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(['$C_{{{}}}$'.format(i) for i in x])\n",
    "plt.xlabel(\"Individual\")\n",
    "plt.ylabel(\"Number of Samples\")\n",
    "plt.legend([\"Class frequency\", \"Weights\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Timestamp for 2021 dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from datetime import datetime\n",
    "\n",
    "def fp2timestamp(fp):\n",
    "    # Regex pattern to match the timestamp\n",
    "    pattern = r'_?(?P<YY>\\d{4})-(?P<MM>\\d{2})-(?P<DD>\\d{1,2})_(?P<hh>\\d{1,2})-(?P<mm>\\d{1,2})-(?P<ss>\\d{1,2})_(image_roi|roi)'\n",
    "    # Get groups\n",
    "    try:\n",
    "        p = list(re.finditer(pattern, fp))[0].groupdict()\n",
    "        # Convert to datetime object\n",
    "        p = f\"{p['YY']}-{p['MM']}-{(p['DD'])}T{p['hh']}::{p['mm']}::{p['ss']}\"\n",
    "        return datetime.timestamp(datetime.strptime(p, '%Y-%m-%dT%H::%M::%S'))\n",
    "    except IndexError:\n",
    "        return 0\n",
    "for tracklet in dataSet['train']:\n",
    "    [fp2timestamp(path) for path in tracklet['paths']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def loadResizeImage(img_path):\n",
    "    size = (244, 244)\n",
    "    # Load the image\n",
    "    img = Image.open(img_path)\n",
    "\n",
    "    # Keep the original image size\n",
    "    old_size = img.size\n",
    "\n",
    "    # Compute resizing ratio\n",
    "    ratio = float(size[0]) / max(old_size)\n",
    "    new_size = tuple([int(x * ratio) for x in old_size])\n",
    "\n",
    "    # Actually resize it\n",
    "    img = img.resize(new_size, Image.ANTIALIAS)\n",
    "\n",
    "    # Paste into centre of black padded image\n",
    "    new_img = Image.new(\"RGB\", (size[0], size[1]))\n",
    "    new_img.paste(img, ((size[0] - new_size[0]) // 2, (size[1] - new_size[1]) // 2))\n",
    "\n",
    "    # Convert to numpy\n",
    "    new_img = numpy.array(new_img, dtype=numpy.uint8)\n",
    "\n",
    "    return new_img\n",
    "\n",
    "# Function to compose images in a grid\n",
    "compose = lambda images, horizontal: numpy.concatenate(\n",
    "    [img / 255 if horizontal == 1 else img for img in images],\n",
    "    axis=horizontal,\n",
    ")\n",
    "\n",
    "topDir = \"/Users/as16542/Downloads/10m32xl88x2b61zlkkgz3fml17\"\n",
    "for i in range(38, 39):\n",
    "    # Sample image from the dataset\n",
    "    trainSet = None\n",
    "    testSet = None\n",
    "    negSet = None\n",
    "    for j in range(len(dataSet[\"train\"])):\n",
    "        if dataSet[\"train\"][j][\"label\"] - 1 == i:\n",
    "            trainSet = dataSet[\"train\"][j][\"paths\"]\n",
    "            break\n",
    "    for j in range(len(dataSet[\"test\"])):\n",
    "        if dataSet[\"test\"][j][\"label\"] - 1 == i:\n",
    "            testSet = dataSet[\"test\"][j][\"paths\"]\n",
    "            break\n",
    "    for j in range(len(dataSet[\"test\"])):\n",
    "        if dataSet[\"test\"][j][\"label\"] - 1 == i+1:\n",
    "            negSet = dataSet[\"test\"][j][\"paths\"]\n",
    "            break\n",
    "    # Take first 5 images\n",
    "    trainSet, testSet, negSet = [os.path.join(topDir, path) for path in trainSet[:5]], [\n",
    "        os.path.join(topDir, path) for path in testSet[:5]\n",
    "    ], [os.path.join(topDir, path) for path in negSet[:5]]\n",
    "\n",
    "    trainSet, testSet = [loadResizeImage(path) for path in trainSet], [loadResizeImage(path) for path in testSet]\n",
    "    negSet = [loadResizeImage(path) for path in negSet]\n",
    "    print(len(trainSet), len(testSet), len(negSet))\n",
    "    composite = compose([compose(trainSet, 1), compose(testSet, 1), compose(negSet, 1)], 0)\n",
    "    plt.imshow(composite)\n",
    "    plt.show()\n",
    "    print(i)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = (10, 10)\n",
    "fig, ax = plt.subplots(1, dpi=100)\n",
    "found = []\n",
    "for item in dataSet['train']:\n",
    "    if item['label'] == 1:\n",
    "        found.append(item)\n",
    "\n",
    "# Take first 5 images\n",
    "trainSet, testSet = [os.path.join(topDir, path) for path in found[0]['paths'][:5]], [\n",
    "    os.path.join(topDir, path) for path in found[1]['paths'][:5]\n",
    "]\n",
    "\n",
    "trainSet, testSet = [loadResizeImage(path) for path in trainSet], [loadResizeImage(path) for path in testSet]\n",
    "composite = compose([compose(trainSet, 1), compose(testSet, 1)], 0)\n",
    "plt.imshow(composite)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "# Save\n",
    "with open('./utils/opencowsTracklets2020V2.json', 'w') as fp:\n",
    "    json.dump(dataSet, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = [len(track['paths']) for track in dataSet['train']]\n",
    "plt.plot(dt)\n",
    "sum(dt) / len(dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.model_zoo as model_zoo\n",
    "import torchvision.models as models\n",
    "import hiddenlayer as hl\n",
    "from tqdm import tqdm\n",
    "from torch import optim\n",
    "import numpy\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from utils.OpenSetCows2021 import OpenSetCows2021TrackLet\n",
    "\n",
    "dataset = OpenSetCows2021TrackLet(\n",
    "    \"/Users/as16542/Downloads/10m32xl88x2b61zlkkgz3fml17\",\n",
    "    \"utils/opencowsTracklets2020V2.json\",\n",
    "    maxSequenceLength=None,\n",
    "    transform=False,\n",
    "    split=\"train\",\n",
    "    trackletChoiceProb = 1,\n",
    ")\n",
    "\n",
    "dataset2 = OpenSetCows2021TrackLet(\n",
    "    \"/Users/as16542/Downloads/10m32xl88x2b61zlkkgz3fml17\",\n",
    "    \"utils/opencowsTracklets2020V2.json\",\n",
    "    maxSequenceLength=None,\n",
    "    transform=False,\n",
    "    split=\"test\",\n",
    "    trackletChoiceProb = 1,\n",
    ")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams[\"figure.figsize\"] = (15, 5)\n",
    "fig = plt.figure()\n",
    "ax = fig.add_axes([0,0,1,1])\n",
    "\n",
    "distribution = numpy.asarray([[k, len(dataset.lookup[k])] for k in dataset.lookup.keys()])\n",
    "distribution2 = numpy.asarray([[k, len(dataset2.lookup[k])] for k in dataset2.lookup.keys()])\n",
    "langs = [str(i) for i in distribution[:,0]]\n",
    "students = distribution[:,1]\n",
    "ax.bar(langs,students)\n",
    "ax.bar(langs,distribution2[:,1])\n",
    "plt.show()\n",
    "\n",
    "dataset3 = OpenSetCows2021TrackLet(\n",
    "    \"/Users/as16542/Downloads/10m32xl88x2b61zlkkgz3fml17\",\n",
    "    \"utils/opencowsTracklets2020V2Combined.json\",\n",
    "    maxSequenceLength=None,\n",
    "    # transform=False,\n",
    "    split=\"train\",\n",
    "    trackletChoiceProb = 1,\n",
    ")\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_axes([0,0,1,1])\n",
    "distribution = numpy.asarray([[k, len(dataset3.lookup[k])] for k in dataset3.lookup.keys()])\n",
    "langs = [str(i) for i in distribution[:,0]]\n",
    "students = distribution[:,1]\n",
    "ax.bar(langs,students)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequenceLengths = [[dataset3.__getitem__(ind)[0].shape[0] for ind in dataset3.lookup[k]] for k in dataset3.lookup.keys()]\n",
    "sequenceLengths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make k-fold validation dataset for AirealCows 2017"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, glob\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "topDIR = '/Users/as16542/Downloads/3owflku95bxsx24643cybxu3qh/*/*/*.jpg'\n",
    "dataSet = {\"test\": [], \"train\": [], \"valid\": []}\n",
    "images = glob.glob(topDIR)\n",
    "images.sort()\n",
    "currentCategory, currentTracklet = 0, 0\n",
    "currentList, trackletImage = [], []\n",
    "element = {}\n",
    "categories = []\n",
    "for directory in images:\n",
    "    elements = directory.split('/')\n",
    "    category, tracklet, image = int(elements[-3]), int(elements[-2]), elements[-1]\n",
    "    if currentCategory != category or currentTracklet != tracklet:\n",
    "        dataSet['train'].append({'paths': trackletImage, 'label': currentCategory})\n",
    "        trackletImage = []\n",
    "        categories.append(category)\n",
    "        currentCategory = category\n",
    "        currentTracklet = tracklet\n",
    "    # if category > 1:\n",
    "    #     break\n",
    "    trackletImage.append(directory.replace('/Users/as16542/Downloads/3owflku95bxsx24643cybxu3qh/', ''))\n",
    "\n",
    "def list_splitter(list_to_split, ratio):\n",
    "    first_half = int(len(list_to_split) * ratio)\n",
    "    return list_to_split[:first_half], list_to_split[first_half:]\n",
    "\n",
    "def chunks(lst, n):\n",
    "    \"\"\"Yield successive n-sized chunks from lst.\"\"\"\n",
    "    for i in range(0, len(lst), n):\n",
    "        yield lst[i:i + n]\n",
    "\n",
    "dataSetFin = {\"test\": [], \"train\": [], \"valid\": []}\n",
    "data = []\n",
    "for category in list(set(categories)):\n",
    "    tracklets = []\n",
    "    for tracklet in dataSet['train']:\n",
    "        if tracklet['label'] == category:\n",
    "            subsequences = list(chunks(tracklet['paths'], 10))\n",
    "            # subsequences = [subsequence for subsequence in subsequences if len(subsequence) >= 5]\n",
    "            subsequences = [\n",
    "                {'paths': subsequence, 'label': category}\n",
    "                for subsequence in subsequences\n",
    "            ]\n",
    "            tracklets+=subsequences\n",
    "    data += tracklets\n",
    "\n",
    "labels = [tracklet['label'] for tracklet in  data]\n",
    "train, test, _, _ = train_test_split(data, labels, test_size=0.2, random_state=42)\n",
    "dataSetFin['train'] = train\n",
    "dataSetFin['test'] = test\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# Generate k folds validation set\n",
    "sKFold = StratifiedKFold(n_splits=3, random_state=None, shuffle=False)\n",
    "i = 0\n",
    "for train_index, test_index in sKFold.split(dataSetFin['train'], [tracklet['label'] for tracklet in  dataSetFin['train']]):\n",
    "    train, test = [], []\n",
    "    print(train_index[:10], test_index[:10])\n",
    "    for j in range(len(train_index)):\n",
    "        train.append(dataSetFin['train'][train_index[j]])\n",
    "    for j in range(len(test_index)):\n",
    "        test.append(dataSetFin['train'][test_index[j]])\n",
    "    dataSetFin['traink{}'.format(i)] = train\n",
    "    dataSetFin['testk{}'.format(i)] = test\n",
    "    i+=1\n",
    "\n",
    "import json\n",
    "# Save\n",
    "with open('./utils/opencowsTracklets2017.json', 'w') as fp:\n",
    "    json.dump(dataSetFin, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from utils.OpenSetCows2021 import OpenSetCows2021TrackLet\n",
    "import numpy\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import matplotlib.pyplot as plt\n",
    "from utils.classWeights import ClassWeights\n",
    "import math\n",
    "\n",
    "batchSize = 25\n",
    "trainingDataset = OpenSetCows2021TrackLet(\n",
    "    \"/Users/as16542/Downloads/10m32xl88x2b61zlkkgz3fml17\",\n",
    "    'utils/opencowsTracklets2020.json',\n",
    "    maxSequenceLength=5,\n",
    "    split='traink2',\n",
    "    trackletChoiceProb = 0.4,\n",
    "    eval=False,\n",
    "    batchSize=batchSize\n",
    ")\n",
    "\n",
    "trainingDataLoader = DataLoader(\n",
    "    trainingDataset, batch_size=batchSize, num_workers=2, shuffle=True\n",
    ")\n",
    "\n",
    "# fig = plt.figure()\n",
    "# ax = fig.add_axes([0,0,1,1])\n",
    "# distribution = numpy.asarray([[k, len(trainingDataset.lookup[k])] for k in trainingDataset.lookup.keys()])\n",
    "# langs = [str(i) for i in distribution[:,0]]\n",
    "# students = distribution[:,1] \n",
    "# ax.bar(langs,students)\n",
    "# plt.show()\n",
    "\n",
    "with open('utils/opencowsTracklets2020.json') as f:\n",
    "    dataSet = json.load(f)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "classFrequency = []\n",
    "for track in dataSet['train']:\n",
    "    classFrequency.append(track['label'])\n",
    "\n",
    "for track in dataSet['test']:\n",
    "    classFrequency.append(track['label'])\n",
    "\n",
    "print('ClassFrequency')\n",
    "fig = plt.figure()\n",
    "ax = fig.add_axes([0,0,1,1])\n",
    "langs = list(range(trainingDataset.numClasses))\n",
    "langs = [str(l) for l in langs]\n",
    "ax.bar(langs, trainingDataset.classFrequency)\n",
    "plt.show()\n",
    "\n",
    "print('SKlearn')\n",
    "fig = plt.figure()\n",
    "ax = fig.add_axes([0,0,1,1])\n",
    "weights = compute_class_weight(class_weight = 'balanced', classes = numpy.unique(classFrequency), y = classFrequency)\n",
    "\n",
    "# weights /= (numpy.sum(weights) * len(langs))\n",
    "ax.bar(langs, weights)\n",
    "plt.show()\n",
    "\n",
    "print('Effective Number of Samples')\n",
    "fig = plt.figure()\n",
    "ax = fig.add_axes([0,0,1,1])\n",
    "weights = ClassWeights(trainingDataset.classFrequency, trainingDataset.numClasses, 'ENS', beta=0.89, normalise=False)()\n",
    "ax.bar(langs, weights)\n",
    "plt.show()\n",
    "\n",
    "print('Inverse Number of Samples')\n",
    "fig = plt.figure()\n",
    "ax = fig.add_axes([0,0,1,1])\n",
    "weights = ClassWeights(trainingDataset.classFrequency, trainingDataset.numClasses, 'INS')()\n",
    "ax.bar(langs, weights)\n",
    "plt.show()\n",
    "\n",
    "print('Inverse Squareroot of Number of Samples')\n",
    "fig = plt.figure()\n",
    "ax = fig.add_axes([0,0,1,1])\n",
    "weights = ClassWeights(trainingDataset.classFrequency, trainingDataset.numClasses, 'ISNS')()\n",
    "ax.bar(langs, weights)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot([i%23 for i in range(92)])\n",
    "\n",
    "betaForENS = numpy.linspace(0.999, 0.92, 50)\n",
    "\n",
    "for i in range(len(betaForENS)):\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_axes([0,0,1,1])\n",
    "    ax.set_title(r\"$\\beta=${}, iteration: {}\".format(betaForENS[i], i))\n",
    "    weights = ClassWeights(trainingDataset.classFrequency, trainingDataset.numClasses, 'ENS', beta=betaForENS[i], normalise=False)() * 100\n",
    "    ax.bar(langs, weights)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pytorch_metric_learning.samplers import MPerClassSampler\n",
    "import matplotlib.pyplot as plt\n",
    "from utils.OpenSetCows2021 import OpenSetCows2021TrackLet\n",
    "from torch.utils.data.sampler import Sampler\n",
    "from pytorch_metric_learning.utils import common_functions as c_f\n",
    "import random\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy\n",
    "import torch\n",
    "from utils.classWeights import ClassWeights\n",
    "from copy import deepcopy\n",
    "\n",
    "class MPerClassTripletSampler(Sampler):\n",
    "  def __init__(self, labels, m, batch_size=None, weights=None, length_before_new_iter=100000):\n",
    "    self.posSampler = MPerClassSampler(labels, m=m, length_before_new_iter=length_before_new_iter, batch_size=batch_size)\n",
    "    self.weights = None\n",
    "    if isinstance(weights, numpy.ndarray):\n",
    "        self.weights = torch.as_tensor(weights, dtype=torch.double)\n",
    "\n",
    "  def __len__(self):\n",
    "    return self.posSampler.list_size\n",
    "\n",
    "  def __iter__(self):\n",
    "      idx_listPos = [0] * self.posSampler.list_size\n",
    "      idx_listNeg = [0] * self.posSampler.list_size\n",
    "      i = 0\n",
    "      num_iters = self.posSampler.calculate_num_iters()\n",
    "      for _ in range(num_iters):\n",
    "          c_f.NUMPY_RANDOM.shuffle(self.posSampler.labels)\n",
    "          curr_label_set_neg = deepcopy(self.posSampler.labels)\n",
    "\n",
    "          if self.posSampler.batch_size is None:\n",
    "              curr_label_set = self.posSampler.labels\n",
    "              c_f.NUMPY_RANDOM.shuffle(curr_label_set_neg)\n",
    "          else:\n",
    "              curr_label_set = self.posSampler.labels[: self.posSampler.batch_size // self.posSampler.m_per_class]\n",
    "              \n",
    "              for l in curr_label_set:\n",
    "                curr_label_set_neg = list(filter(lambda val: val !=  l, curr_label_set_neg) )\n",
    "              curr_label_set_neg = curr_label_set_neg[: self.posSampler.batch_size // self.posSampler.m_per_class]\n",
    "              \n",
    "              if self.weights != None:\n",
    "                  weightedIndeces = torch.multinomial(self.weights[curr_label_set_neg], len(curr_label_set_neg), True)\n",
    "                  curr_label_set_neg = [curr_label_set_neg[index] for index in list(weightedIndeces.numpy())]\n",
    "              # Remove the anchors from the negative set\n",
    "\n",
    "          for label in curr_label_set:\n",
    "              t = self.posSampler.labels_to_indices[label]\n",
    "              idx_listPos[i : i + self.posSampler.m_per_class] = c_f.safe_random_choice(\n",
    "                  t, size=self.posSampler.m_per_class\n",
    "              )\n",
    "\n",
    "              # Remove the anchors from the negative set\n",
    "              negatives = curr_label_set_neg\n",
    "              if self.posSampler.batch_size is None:\n",
    "                  negatives = list(filter(lambda val: val !=  t[0], negatives))\n",
    "\n",
    "              # Assign choice weights\n",
    "              if isinstance(self.weights, numpy.ndarray):\n",
    "                  weightsForSamplingNeg = self.weights[curr_label_set_neg]\n",
    "              else:\n",
    "                  weightsForSamplingNeg = None\n",
    "\n",
    "              tex = random.choices(negatives, weights=weightsForSamplingNeg, k=self.posSampler.m_per_class)\n",
    "\n",
    "              # Assert the the anchor does not appear in the negatives list\n",
    "              assert((t[0] not in tex) == True)\n",
    "              idx_listNeg[i : i + self.posSampler.m_per_class] = tex\n",
    "              i += self.posSampler.m_per_class\n",
    "    #   print(idx_listPos, idx_listNeg)\n",
    "      return iter(zip(idx_listPos, idx_listNeg))\n",
    "\n",
    "trainingDataset = OpenSetCows2021TrackLet(\n",
    "    \"/Users/as16542/Downloads/3owflku95bxsx24643cybxu3qh\",\n",
    "    \"./utils/opencowsTracklets2021.json\",\n",
    "    maxSequenceLength=5,\n",
    "    transform=None,    \n",
    "    trackletChoiceProb = 0.5,\n",
    "    eval=False,\n",
    "    batchSize=100\n",
    ")\n",
    "\n",
    "# Class weighted sampling\n",
    "# print(trainingDataset.numClasses, len(trainingDataset))\n",
    "sampler = MPerClassTripletSampler(\n",
    "    list(range(155)), m=15,\n",
    "    length_before_new_iter=1000,\n",
    "    batch_size=75,\n",
    "    # weights=ClassWeights(trainingDataset.classFrequency, trainingDataset.numClasses, 'ENS', beta=0.92, normalise=False)()\n",
    "    weights=trainingDataset.getClassWeights('IMF')\n",
    "    # weights=None\n",
    ")\n",
    "# print(len(sampler.posSampler))\n",
    "distribuionPos = numpy.zeros(155)\n",
    "distribuionNeg = numpy.zeros(155)\n",
    "for i in range(100):\n",
    "  pos, neg = zip(*iter(sampler))\n",
    "  for classIdx in pos:\n",
    "    distribuionPos[classIdx] += 1\n",
    "  for classIdx in neg:\n",
    "      distribuionNeg[classIdx] += 1\n",
    "\n",
    "# distribuionPos /= len(sampler)\n",
    "# distribuionNeg /= len(sampler)\n",
    "# fig = plt.figure()\n",
    "# ax = fig.add_axes([0,0,1,1])\n",
    "# ax.bar(list(range(155)), trainingDataset.classFrequency)\n",
    "# plt.show()\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_axes([0,0,1,1])\n",
    "ax.bar(list(range(155)), distribuionPos)\n",
    "plt.show()\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_axes([0,0,1,1])\n",
    "ax.bar(list(range(155)), distribuionNeg)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x1124a3550>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/metricLearning/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1358, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/metricLearning/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1322, in _shutdown_workers\n",
      "    w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/metricLearning/lib/python3.8/multiprocessing/process.py\", line 149, in join\n",
      "    res = self._popen.wait(timeout)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/metricLearning/lib/python3.8/multiprocessing/popen_fork.py\", line 44, in wait\n",
      "    if not wait([self.sentinel], timeout):\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/metricLearning/lib/python3.8/multiprocessing/connection.py\", line 931, in wait\n",
      "    ready = selector.select(timeout)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/metricLearning/lib/python3.8/selectors.py\", line 415, in select\n",
      "    fd_event_list = self._selector.poll(timeout)\n",
      "KeyboardInterrupt: \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [26]\u001b[0m, in \u001b[0;36m<cell line: 30>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     29\u001b[0m distribuionNegative \u001b[39m=\u001b[39m numpy\u001b[39m.\u001b[39mzeros(\u001b[39m23\u001b[39m)\n\u001b[1;32m     30\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m100\u001b[39m):\n\u001b[0;32m---> 31\u001b[0m     _, _, _,  positiveLabel, negativeLabel \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39;49m(\u001b[39miter\u001b[39;49m(trainingDataLoader))\n\u001b[1;32m     32\u001b[0m     \u001b[39mfor\u001b[39;00m classIdx \u001b[39min\u001b[39;00m positiveLabel:\n\u001b[1;32m     33\u001b[0m         distribuionPositive[classIdx] \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/metricLearning/lib/python3.8/site-packages/torch/utils/data/dataloader.py:530\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/metricLearning/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=527'>528</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/metricLearning/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=528'>529</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()\n\u001b[0;32m--> <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/metricLearning/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=529'>530</a>\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[1;32m    <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/metricLearning/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=530'>531</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/metricLearning/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=531'>532</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/metricLearning/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=532'>533</a>\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/metricLearning/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=533'>534</a>\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/metricLearning/lib/python3.8/site-packages/torch/utils/data/dataloader.py:1207\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/metricLearning/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=1203'>1204</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_process_data(data)\n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/metricLearning/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=1205'>1206</a>\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_shutdown \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_tasks_outstanding \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m-> <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/metricLearning/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=1206'>1207</a>\u001b[0m idx, data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_data()\n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/metricLearning/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=1207'>1208</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_tasks_outstanding \u001b[39m-\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/metricLearning/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=1208'>1209</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable:\n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/metricLearning/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=1209'>1210</a>\u001b[0m     \u001b[39m# Check for _IterableDatasetStopIteration\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/metricLearning/lib/python3.8/site-packages/torch/utils/data/dataloader.py:1173\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/metricLearning/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=1168'>1169</a>\u001b[0m     \u001b[39m# In this case, `self._data_queue` is a `queue.Queue`,. But we don't\u001b[39;00m\n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/metricLearning/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=1169'>1170</a>\u001b[0m     \u001b[39m# need to call `.task_done()` because we don't use `.join()`.\u001b[39;00m\n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/metricLearning/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=1170'>1171</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/metricLearning/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=1171'>1172</a>\u001b[0m     \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m-> <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/metricLearning/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=1172'>1173</a>\u001b[0m         success, data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_try_get_data()\n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/metricLearning/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=1173'>1174</a>\u001b[0m         \u001b[39mif\u001b[39;00m success:\n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/metricLearning/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=1174'>1175</a>\u001b[0m             \u001b[39mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/metricLearning/lib/python3.8/site-packages/torch/utils/data/dataloader.py:1011\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/metricLearning/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=997'>998</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_try_get_data\u001b[39m(\u001b[39mself\u001b[39m, timeout\u001b[39m=\u001b[39m_utils\u001b[39m.\u001b[39mMP_STATUS_CHECK_INTERVAL):\n\u001b[1;32m    <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/metricLearning/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=998'>999</a>\u001b[0m     \u001b[39m# Tries to fetch data from `self._data_queue` once for a given timeout.\u001b[39;00m\n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/metricLearning/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=999'>1000</a>\u001b[0m     \u001b[39m# This can also be used as inner loop of fetching without timeout, with\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/metricLearning/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=1007'>1008</a>\u001b[0m     \u001b[39m# Returns a 2-tuple:\u001b[39;00m\n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/metricLearning/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=1008'>1009</a>\u001b[0m     \u001b[39m#   (bool: whether successfully get data, any: data if successful else None)\u001b[39;00m\n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/metricLearning/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=1009'>1010</a>\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/metricLearning/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=1010'>1011</a>\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_data_queue\u001b[39m.\u001b[39;49mget(timeout\u001b[39m=\u001b[39;49mtimeout)\n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/metricLearning/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=1011'>1012</a>\u001b[0m         \u001b[39mreturn\u001b[39;00m (\u001b[39mTrue\u001b[39;00m, data)\n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/metricLearning/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=1012'>1013</a>\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/metricLearning/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=1013'>1014</a>\u001b[0m         \u001b[39m# At timeout and error, we manually check whether any worker has\u001b[39;00m\n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/metricLearning/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=1014'>1015</a>\u001b[0m         \u001b[39m# failed. Note that this is the only mechanism for Windows to detect\u001b[39;00m\n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/metricLearning/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=1015'>1016</a>\u001b[0m         \u001b[39m# worker failures.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/metricLearning/lib/python3.8/multiprocessing/queues.py:107\u001b[0m, in \u001b[0;36mQueue.get\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/metricLearning/lib/python3.8/multiprocessing/queues.py?line=104'>105</a>\u001b[0m \u001b[39mif\u001b[39;00m block:\n\u001b[1;32m    <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/metricLearning/lib/python3.8/multiprocessing/queues.py?line=105'>106</a>\u001b[0m     timeout \u001b[39m=\u001b[39m deadline \u001b[39m-\u001b[39m time\u001b[39m.\u001b[39mmonotonic()\n\u001b[0;32m--> <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/metricLearning/lib/python3.8/multiprocessing/queues.py?line=106'>107</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_poll(timeout):\n\u001b[1;32m    <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/metricLearning/lib/python3.8/multiprocessing/queues.py?line=107'>108</a>\u001b[0m         \u001b[39mraise\u001b[39;00m Empty\n\u001b[1;32m    <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/metricLearning/lib/python3.8/multiprocessing/queues.py?line=108'>109</a>\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_poll():\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/metricLearning/lib/python3.8/multiprocessing/connection.py:257\u001b[0m, in \u001b[0;36m_ConnectionBase.poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/metricLearning/lib/python3.8/multiprocessing/connection.py?line=254'>255</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_closed()\n\u001b[1;32m    <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/metricLearning/lib/python3.8/multiprocessing/connection.py?line=255'>256</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_readable()\n\u001b[0;32m--> <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/metricLearning/lib/python3.8/multiprocessing/connection.py?line=256'>257</a>\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_poll(timeout)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/metricLearning/lib/python3.8/multiprocessing/connection.py:424\u001b[0m, in \u001b[0;36mConnection._poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/metricLearning/lib/python3.8/multiprocessing/connection.py?line=422'>423</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_poll\u001b[39m(\u001b[39mself\u001b[39m, timeout):\n\u001b[0;32m--> <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/metricLearning/lib/python3.8/multiprocessing/connection.py?line=423'>424</a>\u001b[0m     r \u001b[39m=\u001b[39m wait([\u001b[39mself\u001b[39;49m], timeout)\n\u001b[1;32m    <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/metricLearning/lib/python3.8/multiprocessing/connection.py?line=424'>425</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mbool\u001b[39m(r)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/metricLearning/lib/python3.8/multiprocessing/connection.py:931\u001b[0m, in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m    <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/metricLearning/lib/python3.8/multiprocessing/connection.py?line=927'>928</a>\u001b[0m     deadline \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mmonotonic() \u001b[39m+\u001b[39m timeout\n\u001b[1;32m    <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/metricLearning/lib/python3.8/multiprocessing/connection.py?line=929'>930</a>\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m--> <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/metricLearning/lib/python3.8/multiprocessing/connection.py?line=930'>931</a>\u001b[0m     ready \u001b[39m=\u001b[39m selector\u001b[39m.\u001b[39;49mselect(timeout)\n\u001b[1;32m    <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/metricLearning/lib/python3.8/multiprocessing/connection.py?line=931'>932</a>\u001b[0m     \u001b[39mif\u001b[39;00m ready:\n\u001b[1;32m    <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/metricLearning/lib/python3.8/multiprocessing/connection.py?line=932'>933</a>\u001b[0m         \u001b[39mreturn\u001b[39;00m [key\u001b[39m.\u001b[39mfileobj \u001b[39mfor\u001b[39;00m (key, events) \u001b[39min\u001b[39;00m ready]\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/metricLearning/lib/python3.8/selectors.py:415\u001b[0m, in \u001b[0;36m_PollLikeSelector.select\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/metricLearning/lib/python3.8/selectors.py?line=412'>413</a>\u001b[0m ready \u001b[39m=\u001b[39m []\n\u001b[1;32m    <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/metricLearning/lib/python3.8/selectors.py?line=413'>414</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/metricLearning/lib/python3.8/selectors.py?line=414'>415</a>\u001b[0m     fd_event_list \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_selector\u001b[39m.\u001b[39;49mpoll(timeout)\n\u001b[1;32m    <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/metricLearning/lib/python3.8/selectors.py?line=415'>416</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mInterruptedError\u001b[39;00m:\n\u001b[1;32m    <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/metricLearning/lib/python3.8/selectors.py?line=416'>417</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m ready\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from pytorch_metric_learning.samplers import MPerClassSampler\n",
    "import matplotlib.pyplot as plt\n",
    "from utils.OpenSetCows2021 import OpenSetCows2021TrackLet\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy\n",
    "from random import choices\n",
    "\n",
    "trainingDataset = OpenSetCows2021TrackLet(\n",
    "    \"/Users/as16542/Downloads/3owflku95bxsx24643cybxu3qh\",\n",
    "    \"./utils/opencowsTracklets2017.json\",\n",
    "    maxSequenceLength=5,\n",
    "    transform=None,    \n",
    "    trackletChoiceProb = 0.5,\n",
    "    eval=False,\n",
    "    batchSize=100\n",
    ")\n",
    "\n",
    "sampler = MPerClassTripletSampler(\n",
    "    list(range(23)), m=5, length_before_new_iter=len(trainingDataset),\n",
    "    batch_size=100\n",
    ")\n",
    "\n",
    "\n",
    "trainingDataLoader = DataLoader(\n",
    "    trainingDataset, batch_size=100, num_workers=1, shuffle=False, pin_memory=True, sampler=sampler\n",
    ")\n",
    "\n",
    "distribuionPositive = numpy.zeros(23)\n",
    "distribuionNegative = numpy.zeros(23)\n",
    "for i in range(100):\n",
    "    _, _, _,  positiveLabel, negativeLabel = next(iter(trainingDataLoader))\n",
    "    for classIdx in positiveLabel:\n",
    "        distribuionPositive[classIdx] += 1\n",
    "\n",
    "    for classIdx in negativeLabel:\n",
    "        distribuionNegative[classIdx] += 1  \n",
    "\n",
    "distribuionNegative /= 100\n",
    "distribuionPositive /= 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = (15, 5)\n",
    "# plot data in grouped manner of bar type\n",
    "print('Positive Sampling')\n",
    "width = 0.40\n",
    "x = numpy.array(range(23))\n",
    "ax = plt.axes()\n",
    "\n",
    "plt.bar(x-0.2, distribuionPositive, width, color='cyan')\n",
    "plt.bar(x+0.2, distribuionNegative, width, color='green')\n",
    "\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(['$C_{{{}}}$'.format(i) for i in range(23)])\n",
    "\n",
    "plt.xlabel(\"Individual\")\n",
    "plt.ylabel(\"Number of Samples\")\n",
    "plt.legend([\"Positive\", \"Negative\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "positiveLabel\n",
    "weights = compute_class_weight(class_weight = 'balanced', classes = numpy.unique(classFrequency), y = classFrequency)\n",
    "population = list(range(23))\n",
    "\n",
    "negSamples = []\n",
    "for label in positiveLabel:\n",
    "    w, p = list(weights), \n",
    "    w.pop(label)\n",
    "    p.pop(label)\n",
    "    negSamples.append(choices(p, w)[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(range(23)).pop(1)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a35bd2a748ff812196078b530039d66aaa336851f47ca82b0a06ab1bf96aa2d4"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('metricLearning': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
