{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "import glob\n",
    "import numpy\n",
    "from PIL import ImageDraw \n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import ImageFont\n",
    "\n",
    "def loadResizeImage(img_path, label=None):\n",
    "    size = (124, 124)\n",
    "\n",
    "    # Load the image\n",
    "    img = Image.open(img_path)\n",
    "    # Keep the original image size\n",
    "    old_size = img.size\n",
    "\n",
    "    # Compute resizing ratio\n",
    "    ratio = float(size[0]) / max(old_size)\n",
    "    new_size = tuple([int(x * ratio) for x in old_size])\n",
    "\n",
    "    # Actually resize it\n",
    "    img = img.resize(new_size, Image.ANTIALIAS)\n",
    "\n",
    "    # Paste into centre of black padded image\n",
    "    new_img = Image.new(\"RGB\", (size[0], size[1]))\n",
    "    new_img.paste(img, ((size[0] - new_size[0]) // 2, (size[1] - new_size[1]) // 2))\n",
    "    if label != None:\n",
    "        draw = ImageDraw.Draw(new_img)\n",
    "        font = ImageFont.truetype(\"/System/Library/Fonts/Supplemental/Arial.ttf\", 12)\n",
    "        draw.text((62, 10),label,(255,255,255),font=font)\n",
    "\n",
    "    # Convert to numpy\n",
    "    new_img = numpy.array(new_img, dtype=numpy.uint8)\n",
    "\n",
    "    return new_img\n",
    "\n",
    "# Function to compose images in a grid\n",
    "compose = lambda images, horizontal: numpy.concatenate(\n",
    "    [img / 255 if horizontal == 1 else img for img in images],\n",
    "    axis=horizontal,\n",
    ")\n",
    "\n",
    "def listDirs(dir):\n",
    "    images = glob.glob(dir + '/*')\n",
    "    timestamps = [os.path.getctime(path) for path in images]\n",
    "    indeces = numpy.argsort(timestamps)\n",
    "    images = [images[idx] for idx in indeces]\n",
    "    return images, indeces\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip3 install xlsxwriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import xlsxwriter\n",
    "# import cv2\n",
    "# from io import BytesIO\n",
    "# # This sorts images based on timestamps. These are used to manually annotate the dataset.\n",
    "# topDir = '/Users/as16542/Downloads/10m32xl88x2b61zlkkgz3fml17/identification/images/test/*'\n",
    "# dirs = glob.glob(topDir)\n",
    "# for dir in dirs:\n",
    "#     img, indeces = listDirs(dir)\n",
    "#     # Create an new Excel file and add a worksheet.\n",
    "#     workbook = xlsxwriter.Workbook('./tracklets/{}.xlsx'.format(dir.split('/')[-1]))\n",
    "#     worksheet = workbook.add_worksheet()\n",
    "#     sheetFormat = workbook.add_format({'text_wrap': True})\n",
    "#     # Widen the first column to make the text clearer.\n",
    "#     worksheet.set_column('A:A', 30, sheetFormat)\n",
    "#     worksheet.set_column('B:B', 17)\n",
    "#     for i in range(len(img)):\n",
    "#         # Insert an image.\n",
    "#         worksheet.set_row(i, 92)\n",
    "#         success, img_numpy = cv2.imencode('.jpg', loadResizeImage(img[i], label=str(i)))\n",
    "#         worksheet.write('A{}'.format(i), img[i])\n",
    "#         worksheet.insert_image('B{}'.format(i), img[i], {'image_data': BytesIO(img_numpy.tobytes())})\n",
    "#     workbook.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# topDir = '/Users/as16542/Downloads/10m32xl88x2b61zlkkgz3fml17/identification/images/test/*'\n",
    "# dirs = glob.glob(topDir)\n",
    "# for dir in dirs:\n",
    "#     img, indeces = listDirs(dir)\n",
    "#     fig, ax = plt.subplots(1, figsize=((len(img) * 124)/500, 124/500), dpi=500)\n",
    "#     img = [loadResizeImage(img[i], label=str(i)) for i in range(len(img))]\n",
    "#     plt.imshow(compose(img, 1), aspect=1)\n",
    "#     [ax.spines[spine].set_visible(False) for spine in [\"top\", \"right\", \"bottom\", \"left\"]]\n",
    "#     ax.axes.get_xaxis().set_ticks([])\n",
    "#     ax.axes.get_yaxis().set_ticks([])\n",
    "#     ax.axis(\"tight\")\n",
    "#     # print(\"{} {}\".format(dir, len(img)))\n",
    "#     plt.savefig(\"./tracklets/{}.png\".format(dir.split('/')[-1]), dpi=500)\n",
    "#     plt.figure().clear()\n",
    "#     plt.close()\n",
    "#     plt.cla()\n",
    "#     plt.clf()\n",
    "#     # break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Open cows 2020 tracklets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import csv\n",
    "import numpy\n",
    "import json\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "# !pip3 install imblearn\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "def listDirs(dir):\n",
    "    images = glob.glob(dir + '/*')\n",
    "    timestamps = [os.path.getctime(path) for path in images]\n",
    "    indeces = numpy.argsort(timestamps)\n",
    "    images = [images[idx] for idx in indeces]\n",
    "    return images, indeces\n",
    "\n",
    "def chunks(lst, n):\n",
    "    \"\"\"Yield successive n-sized chunks from lst.\"\"\"\n",
    "    for i in range(0, len(lst), n):\n",
    "        yield lst[i:i + n]\n",
    "\n",
    "topDir = './tracklets/train/csv/*'\n",
    "dirs = glob.glob(topDir)\n",
    "dataSet = {\"test\": [], \"train\": [], \"valid\": []}\n",
    "ignoreIndex = 1000\n",
    "for dir in dirs:\n",
    "    # Parse the train data\n",
    "    with open(dir) as csv_file:\n",
    "        csv_reader = csv.reader(csv_file, delimiter=',')\n",
    "        data = []\n",
    "        trackletInd = []\n",
    "        for row in csv_reader:\n",
    "            row[0] = row[0].replace('/Users/as16542/Downloads/10m32xl88x2b61zlkkgz3fml17/', '')\n",
    "            category = int(row[0].split('/')[-2])\n",
    "            if category < ignoreIndex:\n",
    "                data.append([row[0], category, int(row[1])])\n",
    "                trackletInd.append(int(row[1]))\n",
    "\n",
    "        dataRow = []\n",
    "        for i in range(len(numpy.unique(trackletInd))):\n",
    "            dataRow += [{'paths':[], 'label': ''}]\n",
    "        for path, category, tracklet in data:\n",
    "            dataRow[tracklet]['label'] = category\n",
    "            dataRow[tracklet]['paths'].append(path)\n",
    "        dataSet['train'] += dataRow\n",
    "\n",
    "# Append data from the test set file\n",
    "topDIR = '/Users/as16542/Downloads/10m32xl88x2b61zlkkgz3fml17/identification/images/test/'\n",
    "with open('utils/openCows2020_test_tracklet.json') as f:\n",
    "    files = json.load(f)\n",
    "    for file in files:\n",
    "        if file['type'] == 'split':\n",
    "            directories, indeces = listDirs(topDIR + file['cowID'])\n",
    "            for split in file['splits']:\n",
    "                if int(file['cowID']) < ignoreIndex:\n",
    "                    sortedIdx = [directories[idx].replace('/Users/as16542/Downloads/10m32xl88x2b61zlkkgz3fml17/', '') for idx in split]\n",
    "                    dataSet['train'].append({\"label\": int(file['cowID']), \"paths\": sortedIdx})\n",
    "        else:\n",
    "            if int(file['cowID']) < ignoreIndex:\n",
    "                directories, indeces = listDirs(topDIR + file['cowID'])\n",
    "                directories = [director.replace('/Users/as16542/Downloads/10m32xl88x2b61zlkkgz3fml17/', '') for director in directories]\n",
    "                dataSet['train'].append({\"label\": int(file['cowID']), \"paths\": directories})\n",
    "\n",
    "# Lets devide the sequences into smaller sequences of length 5\n",
    "data = []\n",
    "for tracklet in dataSet['train']:\n",
    "    label = tracklet['label'] - 1\n",
    "    subsequences = list(chunks(tracklet['paths'], 5))\n",
    "    sequences = []\n",
    "    for sequence in subsequences:\n",
    "        sequence = {'paths': sequence, 'label': label}\n",
    "        sequences.append(sequence)\n",
    "    data += sequences\n",
    "\n",
    "labels = [tracklet['label'] for tracklet in  data]\n",
    "# Now let make the test and train split\n",
    "train, test, _, _ = train_test_split(data, labels, test_size=0.3, random_state=42, stratify=labels)\n",
    "dataSetFin = {\"test\": test, \"train\": train, \"valid\": []}\n",
    "\n",
    "# Generate k folds validation set\n",
    "sKFold = StratifiedKFold(n_splits=3, random_state=42, shuffle=True)\n",
    "i = 0\n",
    "for train_index, test_index in sKFold.split(dataSetFin['train'], [tracklet['label'] for tracklet in  dataSetFin['train']]):\n",
    "    train, test = [], []\n",
    "    for j in range(len(train_index)):\n",
    "        train.append(dataSetFin['train'][train_index[j]])\n",
    "    for j in range(len(test_index)):\n",
    "        test.append(dataSetFin['train'][test_index[j]])\n",
    "\n",
    "    dataSetFin['traink{}'.format(i)] = train\n",
    "    dataSetFin['testk{}'.format(i)] = test\n",
    "    i+=1\n",
    "\n",
    "import json\n",
    "# Save\n",
    "with open('./utils/opencowsTracklets2020.json', 'w') as fp:\n",
    "    json.dump(dataSetFin, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "classFrequency = numpy.zeros(numpy.unique(labels).shape)\n",
    "\n",
    "def labels_to_class_weights(labels, nc=80): \n",
    "    # Get class weights (inverse frequency) from training labels \n",
    "    classes = numpy.asarray(labels)\n",
    "    weights = numpy.bincount(classes, minlength=nc)  # occurences per class \n",
    "    weights[weights == 0] = 1  # replace empty bins with 1 \n",
    "    weights = 1 / weights  # number of targets per class \n",
    "    weights /= weights.sum()  # normalize \n",
    "    return weights\n",
    "\n",
    "for track in dataSetFin['traink0']:\n",
    "    classFrequency[track['label']] += 1\n",
    "\n",
    "# for track in data:\n",
    "#     classFrequency[track['label']] += 1\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (15, 5)\n",
    "width = 0.40\n",
    "x = numpy.unique(labels)\n",
    "ax = plt.axes()\n",
    "# plt.bar(x-0.2, classFrequency, width, color='cyan')\n",
    "plt.bar(x-0.2, classFrequency / numpy.sum(classFrequency), width, color='cyan')\n",
    "plt.bar(x+0.2, labels_to_class_weights(labels, nc=len(x)), width, color='green')\n",
    "\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(['$C_{{{}}}$'.format(i) for i in x])\n",
    "plt.xlabel(\"Individual\")\n",
    "plt.ylabel(\"Number of Samples\")\n",
    "plt.legend([\"Class frequency\", \"Weights\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "topDIR = '/Users/as16542/Downloads/10m32xl88x2b61zlkkgz3fml17/identification/images/train/'\n",
    "dataSet = {\"test\": [], \"train\": [], \"valid\": []}\n",
    "with open('utils/openCows2020_train_tracklet.json') as f:\n",
    "    files = json.load(f)\n",
    "    for file in files:\n",
    "        if file['type'] == 'split':\n",
    "            directories, indeces = listDirs(topDIR + file['cowID'])\n",
    "            for split in file['splits']:\n",
    "                sortedIdx = [directories[idx].replace('/Users/as16542/Downloads/10m32xl88x2b61zlkkgz3fml17/', '') for idx in split]\n",
    "                dataSet['train'].append({\"label\": int(file['cowID']), \"paths\": sortedIdx})\n",
    "        else:\n",
    "            directories, indeces = listDirs(topDIR + file['cowID'])\n",
    "            directories = [director.replace('/Users/as16542/Downloads/10m32xl88x2b61zlkkgz3fml17/', '') for director in directories]\n",
    "            dataSet['train'].append({\"label\": int(file['cowID']), \"paths\": directories})\n",
    "\n",
    "topDIR = '/Users/as16542/Downloads/10m32xl88x2b61zlkkgz3fml17/identification/images/test/'\n",
    "with open('utils/openCows2020_test_tracklet.json') as f:\n",
    "    files = json.load(f)\n",
    "    for file in files:\n",
    "        if file['type'] == 'split':\n",
    "            directories, indeces = listDirs(topDIR + file['cowID'])\n",
    "            for split in file['splits']:\n",
    "                sortedIdx = [directories[idx].replace('/Users/as16542/Downloads/10m32xl88x2b61zlkkgz3fml17/', '') for idx in split]\n",
    "                dataSet['test'].append({\"label\": int(file['cowID']), \"paths\": sortedIdx})\n",
    "        else:\n",
    "            directories, indeces = listDirs(topDIR + file['cowID'])\n",
    "            directories = [director.replace('/Users/as16542/Downloads/10m32xl88x2b61zlkkgz3fml17/', '') for director in directories]\n",
    "            dataSet['test'].append({\"label\": int(file['cowID']), \"paths\": directories})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = [len(track['paths']) for track in dataSet['test']]\n",
    "plt.plot(dt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2021 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "import glob\n",
    "import numpy\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def chunks(lst, n):\n",
    "    \"\"\"Yield successive n-sized chunks from lst.\"\"\"\n",
    "    for i in range(0, len(lst), n):\n",
    "        yield lst[i:i + n]\n",
    "\n",
    "def listDirs(dir):\n",
    "    images = glob.glob(dir + '/*')\n",
    "    timestamps = [os.path.getctime(path) for path in images]\n",
    "    indeces = numpy.argsort(timestamps)\n",
    "    images = [images[idx] for idx in indeces]\n",
    "    return images\n",
    "\n",
    "topDir = '/Users/as16542/Downloads/4vnrca7qw1642qlwxjadp87h7/Sub-levels/Identification/Train/RGBDCows2020/Identification/RGB'\n",
    "dataSet = {\"test\": [], \"train\": [], \"valid\": []}\n",
    "\n",
    "# Parse the train data\n",
    "with open('utils/correct.csv') as csv_file:\n",
    "    csv_reader = csv.reader(csv_file, delimiter=',')\n",
    "    line_count = 0\n",
    "    for row in csv_reader:\n",
    "        if line_count > 0 and line_count < 465 and row[6] != 'black':\n",
    "            label = row[4] if row[4] != '' else row[2]\n",
    "            if label != '':\n",
    "                dirs = [dir.replace('/Users/as16542/Downloads/4vnrca7qw1642qlwxjadp87h7/', '') for dir in listDirs(os.path.join(topDir, row[1]))]\n",
    "                # Split into smaller sequences\n",
    "                subsequences = list(chunks(dirs, 10))\n",
    "                subsequences = [\n",
    "                    {'paths': subsequence, 'label': int(label)}\n",
    "                    for subsequence in subsequences\n",
    "                ]\n",
    "                dataSet['train'] += subsequences\n",
    "        line_count += 1\n",
    "\n",
    "# Parse the test data\n",
    "labels = list(set([item['label'] for item in dataSet[\"train\"]]))\n",
    "topDir = '/Users/as16542/Downloads/4vnrca7qw1642qlwxjadp87h7/Sub-levels/Identification/Test/'\n",
    "for label in labels:\n",
    "    path = os.path.join(topDir, '{:>03}'.format(label))\n",
    "    dirs = [dir.replace('/Users/as16542/Downloads/4vnrca7qw1642qlwxjadp87h7/', '') for dir in listDirs(path)]\n",
    "    # Split into smaller sequences\n",
    "    subsequences = list(chunks(dirs, 10))\n",
    "    subsequences = [\n",
    "        {'paths': subsequence, 'label': int(label)}\n",
    "        for subsequence in subsequences\n",
    "    ]\n",
    "    dataSet['test'] += subsequences    \n",
    "    # dataSet[\"test\"].append({'label': int(label), 'paths': dirs})\n",
    "\n",
    "# Since we omitted black cows we need to remove some classes and reindex the labels again\n",
    "labels = list(set([item['label'] for item in dataSet[\"train\"]] + [item['label'] for item in dataSet[\"test\"]]))\n",
    "hotEncodeMap = {}\n",
    "for i in range(len(labels)):\n",
    "    hotEncodeMap[labels[i]] = i\n",
    "\n",
    "# Now we can use the map the relabel the dataset\n",
    "for split in dataSet.keys():\n",
    "    for i in range(len(dataSet[split])):\n",
    "        dataSet[split][i]['label'] = hotEncodeMap[dataSet[split][i]['label']]\n",
    "\n",
    "# Prepare for k-fold splits\n",
    "data = dataSet['train'] + dataSet['test']\n",
    "labels = [item['label'] for item in data]\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# Generate k folds validation set\n",
    "sKFold = StratifiedKFold(n_splits=3, random_state=None, shuffle=False)\n",
    "dataSetFin = {\"test\": [], \"train\": [], \"valid\": []}\n",
    "i = 0\n",
    "for train_index, test_index in sKFold.split(data, labels):\n",
    "    train, test = [], []\n",
    "    for j in range(len(train_index)):\n",
    "        train.append(data[train_index[j]])\n",
    "    for j in range(len(test_index)):\n",
    "        test.append(data[test_index[j]])\n",
    "    dataSetFin['traink{}'.format(i)] = train\n",
    "    dataSetFin['testk{}'.format(i)] = test\n",
    "    i+=1\n",
    "\n",
    "# Now let make the test and train split\n",
    "train, test, _, _ = train_test_split(data, labels, test_size=0.3, random_state=42, stratify=labels)\n",
    "dataSetFin['train'] = train\n",
    "dataSetFin['test'] = test\n",
    "\n",
    "import json\n",
    "# Save\n",
    "with open('./utils/opencowsTracklets2021.json', 'w') as fp:\n",
    "    json.dump(dataSetFin, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "classFrequency = numpy.zeros(numpy.unique(labels).shape)\n",
    "\n",
    "def labels_to_class_weights(labels, nc=80): \n",
    "    # Get class weights (inverse frequency) from training labels \n",
    "    classes = numpy.asarray(labels)\n",
    "    weights = numpy.bincount(classes, minlength=nc)  # occurences per class \n",
    "    weights[weights == 0] = 1  # replace empty bins with 1 \n",
    "    weights = 1 / weights  # number of targets per class \n",
    "    weights /= weights.sum()  # normalize \n",
    "    return weights\n",
    "\n",
    "for track in dataSetFin['traink0']:\n",
    "    classFrequency[track['label']] += 1\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (15, 5)\n",
    "width = 0.40\n",
    "x = numpy.unique(labels)\n",
    "ax = plt.axes()\n",
    "# plt.bar(x-0.2, classFrequency, width, color='cyan')\n",
    "plt.bar(x-0.2, classFrequency / numpy.sum(classFrequency), width, color='cyan')\n",
    "plt.bar(x+0.2, labels_to_class_weights(labels, nc=len(x)), width, color='green')\n",
    "\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(['$C_{{{}}}$'.format(i) for i in x])\n",
    "plt.xlabel(\"Individual\")\n",
    "plt.ylabel(\"Number of Samples\")\n",
    "plt.legend([\"Class frequency\", \"Weights\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Timestamp for 2021 dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from datetime import datetime\n",
    "\n",
    "def fp2timestamp(fp):\n",
    "    # Regex pattern to match the timestamp\n",
    "    pattern = r'_?(?P<YY>\\d{4})-(?P<MM>\\d{2})-(?P<DD>\\d{1,2})_(?P<hh>\\d{1,2})-(?P<mm>\\d{1,2})-(?P<ss>\\d{1,2})_(image_roi|roi)'\n",
    "    # Get groups\n",
    "    try:\n",
    "        p = list(re.finditer(pattern, fp))[0].groupdict()\n",
    "        # Convert to datetime object\n",
    "        p = f\"{p['YY']}-{p['MM']}-{(p['DD'])}T{p['hh']}::{p['mm']}::{p['ss']}\"\n",
    "        return datetime.timestamp(datetime.strptime(p, '%Y-%m-%dT%H::%M::%S'))\n",
    "    except IndexError:\n",
    "        return 0\n",
    "for tracklet in dataSet['train']:\n",
    "    [fp2timestamp(path) for path in tracklet['paths']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def loadResizeImage(img_path):\n",
    "    size = (244, 244)\n",
    "    # Load the image\n",
    "    img = Image.open(img_path)\n",
    "\n",
    "    # Keep the original image size\n",
    "    old_size = img.size\n",
    "\n",
    "    # Compute resizing ratio\n",
    "    ratio = float(size[0]) / max(old_size)\n",
    "    new_size = tuple([int(x * ratio) for x in old_size])\n",
    "\n",
    "    # Actually resize it\n",
    "    img = img.resize(new_size, Image.ANTIALIAS)\n",
    "\n",
    "    # Paste into centre of black padded image\n",
    "    new_img = Image.new(\"RGB\", (size[0], size[1]))\n",
    "    new_img.paste(img, ((size[0] - new_size[0]) // 2, (size[1] - new_size[1]) // 2))\n",
    "\n",
    "    # Convert to numpy\n",
    "    new_img = numpy.array(new_img, dtype=numpy.uint8)\n",
    "\n",
    "    return new_img\n",
    "\n",
    "# Function to compose images in a grid\n",
    "compose = lambda images, horizontal: numpy.concatenate(\n",
    "    [img / 255 if horizontal == 1 else img for img in images],\n",
    "    axis=horizontal,\n",
    ")\n",
    "\n",
    "topDir = \"/Users/as16542/Downloads/10m32xl88x2b61zlkkgz3fml17\"\n",
    "for i in range(38, 39):\n",
    "    # Sample image from the dataset\n",
    "    trainSet = None\n",
    "    testSet = None\n",
    "    negSet = None\n",
    "    for j in range(len(dataSet[\"train\"])):\n",
    "        if dataSet[\"train\"][j][\"label\"] - 1 == i:\n",
    "            trainSet = dataSet[\"train\"][j][\"paths\"]\n",
    "            break\n",
    "    for j in range(len(dataSet[\"test\"])):\n",
    "        if dataSet[\"test\"][j][\"label\"] - 1 == i:\n",
    "            testSet = dataSet[\"test\"][j][\"paths\"]\n",
    "            break\n",
    "    for j in range(len(dataSet[\"test\"])):\n",
    "        if dataSet[\"test\"][j][\"label\"] - 1 == i+1:\n",
    "            negSet = dataSet[\"test\"][j][\"paths\"]\n",
    "            break\n",
    "    # Take first 5 images\n",
    "    trainSet, testSet, negSet = [os.path.join(topDir, path) for path in trainSet[:5]], [\n",
    "        os.path.join(topDir, path) for path in testSet[:5]\n",
    "    ], [os.path.join(topDir, path) for path in negSet[:5]]\n",
    "\n",
    "    trainSet, testSet = [loadResizeImage(path) for path in trainSet], [loadResizeImage(path) for path in testSet]\n",
    "    negSet = [loadResizeImage(path) for path in negSet]\n",
    "    print(len(trainSet), len(testSet), len(negSet))\n",
    "    composite = compose([compose(trainSet, 1), compose(testSet, 1), compose(negSet, 1)], 0)\n",
    "    plt.imshow(composite)\n",
    "    plt.show()\n",
    "    print(i)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = (10, 10)\n",
    "fig, ax = plt.subplots(1, dpi=100)\n",
    "found = []\n",
    "for item in dataSet['train']:\n",
    "    if item['label'] == 1:\n",
    "        found.append(item)\n",
    "\n",
    "# Take first 5 images\n",
    "trainSet, testSet = [os.path.join(topDir, path) for path in found[0]['paths'][:5]], [\n",
    "    os.path.join(topDir, path) for path in found[1]['paths'][:5]\n",
    "]\n",
    "\n",
    "trainSet, testSet = [loadResizeImage(path) for path in trainSet], [loadResizeImage(path) for path in testSet]\n",
    "composite = compose([compose(trainSet, 1), compose(testSet, 1)], 0)\n",
    "plt.imshow(composite)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "# Save\n",
    "with open('./utils/opencowsTracklets2020V2.json', 'w') as fp:\n",
    "    json.dump(dataSet, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = [len(track['paths']) for track in dataSet['train']]\n",
    "plt.plot(dt)\n",
    "sum(dt) / len(dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.model_zoo as model_zoo\n",
    "import torchvision.models as models\n",
    "import hiddenlayer as hl\n",
    "from tqdm import tqdm\n",
    "from torch import optim\n",
    "import numpy\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from utils.OpenSetCows2021 import OpenSetCows2021TrackLet\n",
    "\n",
    "dataset = OpenSetCows2021TrackLet(\n",
    "    \"/Users/as16542/Downloads/10m32xl88x2b61zlkkgz3fml17\",\n",
    "    \"utils/opencowsTracklets2020V2.json\",\n",
    "    maxSequenceLength=None,\n",
    "    transform=False,\n",
    "    split=\"train\",\n",
    "    trackletChoiceProb = 1,\n",
    ")\n",
    "\n",
    "dataset2 = OpenSetCows2021TrackLet(\n",
    "    \"/Users/as16542/Downloads/10m32xl88x2b61zlkkgz3fml17\",\n",
    "    \"utils/opencowsTracklets2020V2.json\",\n",
    "    maxSequenceLength=None,\n",
    "    transform=False,\n",
    "    split=\"test\",\n",
    "    trackletChoiceProb = 1,\n",
    ")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams[\"figure.figsize\"] = (15, 5)\n",
    "fig = plt.figure()\n",
    "ax = fig.add_axes([0,0,1,1])\n",
    "\n",
    "distribution = numpy.asarray([[k, len(dataset.lookup[k])] for k in dataset.lookup.keys()])\n",
    "distribution2 = numpy.asarray([[k, len(dataset2.lookup[k])] for k in dataset2.lookup.keys()])\n",
    "langs = [str(i) for i in distribution[:,0]]\n",
    "students = distribution[:,1]\n",
    "ax.bar(langs,students)\n",
    "ax.bar(langs,distribution2[:,1])\n",
    "plt.show()\n",
    "\n",
    "dataset3 = OpenSetCows2021TrackLet(\n",
    "    \"/Users/as16542/Downloads/10m32xl88x2b61zlkkgz3fml17\",\n",
    "    \"utils/opencowsTracklets2020V2Combined.json\",\n",
    "    maxSequenceLength=None,\n",
    "    # transform=False,\n",
    "    split=\"train\",\n",
    "    trackletChoiceProb = 1,\n",
    ")\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_axes([0,0,1,1])\n",
    "distribution = numpy.asarray([[k, len(dataset3.lookup[k])] for k in dataset3.lookup.keys()])\n",
    "langs = [str(i) for i in distribution[:,0]]\n",
    "students = distribution[:,1]\n",
    "ax.bar(langs,students)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequenceLengths = [[dataset3.__getitem__(ind)[0].shape[0] for ind in dataset3.lookup[k]] for k in dataset3.lookup.keys()]\n",
    "sequenceLengths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make k-fold validation dataset for AirealCows 2017"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, glob\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "topDIR = '/Users/as16542/Downloads/3owflku95bxsx24643cybxu3qh/*/*/*.jpg'\n",
    "dataSet = {\"test\": [], \"train\": [], \"valid\": []}\n",
    "images = glob.glob(topDIR)\n",
    "images.sort()\n",
    "currentCategory, currentTracklet = 0, 0\n",
    "currentList, trackletImage = [], []\n",
    "element = {}\n",
    "categories = []\n",
    "for directory in images:\n",
    "    elements = directory.split('/')\n",
    "    category, tracklet, image = int(elements[-3]), int(elements[-2]), elements[-1]\n",
    "    if currentCategory != category or currentTracklet != tracklet:\n",
    "        dataSet['train'].append({'paths': trackletImage, 'label': currentCategory})\n",
    "        trackletImage = []\n",
    "        categories.append(category)\n",
    "        currentCategory = category\n",
    "        currentTracklet = tracklet\n",
    "    # if category > 1:\n",
    "    #     break\n",
    "    trackletImage.append(directory.replace('/Users/as16542/Downloads/3owflku95bxsx24643cybxu3qh/', ''))\n",
    "\n",
    "def list_splitter(list_to_split, ratio):\n",
    "    first_half = int(len(list_to_split) * ratio)\n",
    "    return list_to_split[:first_half], list_to_split[first_half:]\n",
    "\n",
    "def chunks(lst, n):\n",
    "    \"\"\"Yield successive n-sized chunks from lst.\"\"\"\n",
    "    for i in range(0, len(lst), n):\n",
    "        yield lst[i:i + n]\n",
    "\n",
    "dataSetFin = {\"test\": [], \"train\": [], \"valid\": []}\n",
    "data = []\n",
    "for category in list(set(categories)):\n",
    "    tracklets = []\n",
    "    for tracklet in dataSet['train']:\n",
    "        if tracklet['label'] == category:\n",
    "            subsequences = list(chunks(tracklet['paths'], 10))\n",
    "            # subsequences = [subsequence for subsequence in subsequences if len(subsequence) >= 5]\n",
    "            subsequences = [\n",
    "                {'paths': subsequence, 'label': category}\n",
    "                for subsequence in subsequences\n",
    "            ]\n",
    "            tracklets+=subsequences\n",
    "    data += tracklets\n",
    "\n",
    "labels = [tracklet['label'] for tracklet in  data]\n",
    "train, test, _, _ = train_test_split(data, labels, test_size=0.2, random_state=42)\n",
    "dataSetFin['train'] = train\n",
    "dataSetFin['test'] = test\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# Generate k folds validation set\n",
    "sKFold = StratifiedKFold(n_splits=3, random_state=None, shuffle=False)\n",
    "i = 0\n",
    "for train_index, test_index in sKFold.split(dataSetFin['train'], [tracklet['label'] for tracklet in  dataSetFin['train']]):\n",
    "    train, test = [], []\n",
    "    print(train_index[:10], test_index[:10])\n",
    "    for j in range(len(train_index)):\n",
    "        train.append(dataSetFin['train'][train_index[j]])\n",
    "    for j in range(len(test_index)):\n",
    "        test.append(dataSetFin['train'][test_index[j]])\n",
    "    dataSetFin['traink{}'.format(i)] = train\n",
    "    dataSetFin['testk{}'.format(i)] = test\n",
    "    i+=1\n",
    "\n",
    "import json\n",
    "# Save\n",
    "with open('./utils/opencowsTracklets2017.json', 'w') as fp:\n",
    "    json.dump(dataSetFin, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from utils.OpenSetCows2021 import OpenSetCows2021TrackLet\n",
    "import numpy\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import matplotlib.pyplot as plt\n",
    "from utils.classWeights import ClassWeights\n",
    "import math\n",
    "\n",
    "batchSize = 25\n",
    "trainingDataset = OpenSetCows2021TrackLet(\n",
    "    \"/Users/as16542/Downloads/10m32xl88x2b61zlkkgz3fml17\",\n",
    "    'utils/opencowsTracklets2020.json',\n",
    "    maxSequenceLength=5,\n",
    "    split='traink2',\n",
    "    trackletChoiceProb = 0.4,\n",
    "    eval=False,\n",
    "    batchSize=batchSize\n",
    ")\n",
    "\n",
    "trainingDataLoader = DataLoader(\n",
    "    trainingDataset, batch_size=batchSize, num_workers=2, shuffle=True\n",
    ")\n",
    "\n",
    "# fig = plt.figure()\n",
    "# ax = fig.add_axes([0,0,1,1])\n",
    "# distribution = numpy.asarray([[k, len(trainingDataset.lookup[k])] for k in trainingDataset.lookup.keys()])\n",
    "# langs = [str(i) for i in distribution[:,0]]\n",
    "# students = distribution[:,1] \n",
    "# ax.bar(langs,students)\n",
    "# plt.show()\n",
    "\n",
    "with open('utils/opencowsTracklets2020.json') as f:\n",
    "    dataSet = json.load(f)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "classFrequency = []\n",
    "for track in dataSet['train']:\n",
    "    classFrequency.append(track['label'])\n",
    "\n",
    "for track in dataSet['test']:\n",
    "    classFrequency.append(track['label'])\n",
    "\n",
    "print('ClassFrequency')\n",
    "fig = plt.figure()\n",
    "ax = fig.add_axes([0,0,1,1])\n",
    "langs = list(range(trainingDataset.numClasses))\n",
    "langs = [str(l) for l in langs]\n",
    "ax.bar(langs, trainingDataset.classFrequency)\n",
    "plt.show()\n",
    "\n",
    "print('SKlearn')\n",
    "fig = plt.figure()\n",
    "ax = fig.add_axes([0,0,1,1])\n",
    "weights = compute_class_weight(class_weight = 'balanced', classes = numpy.unique(classFrequency), y = classFrequency)\n",
    "\n",
    "# weights /= (numpy.sum(weights) * len(langs))\n",
    "ax.bar(langs, weights)\n",
    "plt.show()\n",
    "\n",
    "print('Effective Number of Samples')\n",
    "fig = plt.figure()\n",
    "ax = fig.add_axes([0,0,1,1])\n",
    "weights = ClassWeights(trainingDataset.classFrequency, trainingDataset.numClasses, 'ENS', beta=0.89, normalise=False)()\n",
    "ax.bar(langs, weights)\n",
    "plt.show()\n",
    "\n",
    "print('Inverse Number of Samples')\n",
    "fig = plt.figure()\n",
    "ax = fig.add_axes([0,0,1,1])\n",
    "weights = ClassWeights(trainingDataset.classFrequency, trainingDataset.numClasses, 'INS')()\n",
    "ax.bar(langs, weights)\n",
    "plt.show()\n",
    "\n",
    "print('Inverse Squareroot of Number of Samples')\n",
    "fig = plt.figure()\n",
    "ax = fig.add_axes([0,0,1,1])\n",
    "weights = ClassWeights(trainingDataset.classFrequency, trainingDataset.numClasses, 'ISNS')()\n",
    "ax.bar(langs, weights)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot([i%23 for i in range(92)])\n",
    "\n",
    "betaForENS = numpy.linspace(0.999, 0.92, 50)\n",
    "\n",
    "for i in range(len(betaForENS)):\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_axes([0,0,1,1])\n",
    "    ax.set_title(r\"$\\beta=${}, iteration: {}\".format(betaForENS[i], i))\n",
    "    weights = ClassWeights(trainingDataset.classFrequency, trainingDataset.numClasses, 'ENS', beta=betaForENS[i], normalise=False)() * 100\n",
    "    ax.bar(langs, weights)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeMAAAE/CAYAAAB1i6tsAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAT4UlEQVR4nO3dbcxkZ3kf8P9VO3GBFMXUC3V2TdeNTBobJRC2llvaioS2diDC9APSoiZYKpUr5KSkSlvWRWraD5asviQtUqF1A8U0FMtKIFgxpLhuWlSJ4CyUYBvjsoldWOzipagNaiUnJlc/zHEyWT/79rzdc2Z+P2k0M/ecmee+npk5/3Pf5zznqe4OADDOHxndAQDYdMIYAAYTxgAwmDAGgMGEMQAMJowBYLCLR3fgXC677LI+fPjw6G4AwAX5zGc+8/XuPnA+y658GB8+fDjHjx8f3Q0AuCBV9T/Od1nT1AAwmDAGgMGEMQAMJowBYDBhDACDCWMAGEwYA8BgwhgABhPGADCYMAaAwYQxAAwmjAFgMGEMwFo7fOzeHD527+hunJUwBoDBhDEADCaMAWAwYQwAgwljABhMGAPAYMIYAAYTxgAwmDAGgMGEMQAMJowBYDBhDACDCWMAGOycYVxVV1TVr1bVI1X1cFW9fWp/UVXdV1Vfmq4vXXrOrVV1oqoerarrl9pfVVUPTo+9q6pqb8oCgPk4n5HxM0l+qru/N8l1SW6pqquTHEtyf3dfleT+6X6mx44muSbJDUneXVUXTa/1niQ3J7lqutywi7UAwCydM4y7+8nu/ux0+5tJHklyMMmNSe6cFrszyRun2zcmuau7n+7ux5KcSHJtVV2e5IXd/anu7iQfWHoOAGysC9pnXFWHk7wyyaeTvKS7n0wWgZ3kxdNiB5N8ZelpJ6e2g9Pt09sBYKOddxhX1Xck+cUkP9ndv322Rbdo67O0b/Wzbq6q41V1/NSpU+fbRQCYpfMK46r6tiyC+IPd/eGp+WvT1HOm66em9pNJrlh6+qEkT0zth7Zof47uvqO7j3T3kQMHDpxvLQAwS+dzNHUleW+SR7r7Z5YeuifJTdPtm5J8dKn9aFVdUlVXZnGg1gPTVPY3q+q66TXfsvQcANhYF5/HMq9O8mNJHqyqz01tfz/J7Unurqq3JvlykjclSXc/XFV3J/lCFkdi39Ld35qe97Yk70/yvCQfny4AsNHOGcbd/V+z9f7eJHntGZ5zW5Lbtmg/nuTlF9JBAFh3zsAFAIMJYwAYTBgDwGDCGAAGE8YAMJgwBoDBhDEADCaMAWAwYQwAgwljABhMGAPAYMIYAAYTxgAwmDAGgMGEMQAMJowBYDBhDDNz+Ni9OXzs3tHdAHaRMAaAwYQxAAwmjAFgMGEMAIMJYwAYTBgDwGDCGAAGE8YAMJgwBoDBhDEADCaMAWAwYQwAgwljABhMGAPAYMIYAAYTxgAwmDAGgMGEMQAMJowBYDBhDACDCWNm7fCxe3P42L2juwGwI8IYAAYTxgAwmDAGgMGEMQAMJowBYDBhDACDCWMAGEwYA8BgwhgABhPGADCYMAaAwYQxAAwmjAFgMGEMAIMJYwAYTBgDwGDCGAAGO2cYV9X7quqpqnpoqe0fVtVXq+pz0+V1S4/dWlUnqurRqrp+qf1VVfXg9Ni7qqp2vxwA5urwsXtz+Ni9o7sxxPmMjN+f5IYt2n+2u18xXT6WJFV1dZKjSa6ZnvPuqrpoWv49SW5OctV02eo1AWDjnDOMu/uTSb5xnq93Y5K7uvvp7n4syYkk11bV5Ule2N2f6u5O8oEkb9xmnwFgrexkn/GPV9Xnp2nsS6e2g0m+srTMyant4HT79HYA2HjbDeP3JPnuJK9I8mSSfza1b7UfuM/SvqWqurmqjlfV8VOnTm2ziwAwD9sK4+7+Wnd/q7t/L8m/SXLt9NDJJFcsLXooyRNT+6Et2s/0+nd095HuPnLgwIHtdBEAZmNbYTztA37WX03y7JHW9yQ5WlWXVNWVWRyo9UB3P5nkm1V13XQU9VuSfHQH/QaAtXHxuRaoqg8leU2Sy6rqZJKfTvKaqnpFFlPNjyf5m0nS3Q9X1d1JvpDkmSS3dPe3ppd6WxZHZj8vycenCwBsvHOGcXe/eYvm955l+duS3LZF+/EkL7+g3gHABnAGLgAYTBgDwGDCGAAGE8YAMJgwZts2+aTuALtJGAPAYMIYAAYTxgAwmDAGgMGEMQAMJowBZsJfMKwvYQwAgwljABhMGAPAYMIYAAYTxgAwmDAGYEcc5b1zwhgABhPGADCYMAaAwYQxAAwmjIGV5KAgNokwBoDBhDEADCaMAWAwYQwAgwljABhMGAPAYMIYAAYTxgAwmDAGgMGEMQAMJowBYDBhDACDCWPgvPjHDbB3hDEADCaMAWAwYbxDpu4A2ClhDLChDCZWhzAGgMEuHt0BAPaX0fDqMTIGYFeY9t4+YQwAgwljABhMGAPAYMIYAAYTxgAwmDDeII50BFhNwhjYaDZSWQXCGAAGE8YAMJgwZu1sNe1oKhJYZcIYAAYTxgAwmDAGgMHOGcZV9b6qeqqqHlpqe1FV3VdVX5quL1167NaqOlFVj1bV9Uvtr6qqB6fH3lVVtfvlMIp9sgDbdz4j4/cnueG0tmNJ7u/uq5LcP91PVV2d5GiSa6bnvLuqLpqe854kNye5arqc/prw+4Q7rDff8T/snGHc3Z9M8o3Tmm9Mcud0+84kb1xqv6u7n+7ux5KcSHJtVV2e5IXd/anu7iQfWHoOAGy07e4zfkl3P5kk0/WLp/aDSb6ytNzJqe3gdPv0dgazdQow3m4fwLXVfuA+S/vWL1J1c1Udr6rjp06d2rXOAcAq2m4Yf22aes50/dTUfjLJFUvLHUryxNR+aIv2LXX3Hd19pLuPHDhwYJtdBIB52G4Y35Pkpun2TUk+utR+tKouqaorszhQ64FpKvubVXXddBT1W5aeAwAb7eJzLVBVH0rymiSXVdXJJD+d5PYkd1fVW5N8OcmbkqS7H66qu5N8IckzSW7p7m9NL/W2LI7Mfl6Sj08XANh45wzj7n7zGR567RmWvy3JbVu0H0/y8gvqHQBsAGfgWlOOkp4f7xlsLmEMsGZs2M2PMD4HH2qA/bWJ611hDLAGNjHA1okwBoDBhPEasWUMME/n/NMmmAsbIqvj2ffi8dtfP7gnMA9GxgAwmDAG2CG7iNgpYQwAgwljgF1klMx2CGMAGGyjwtgWK6tiNz6LPs+wPjYqjAFgFQljABhMGAPAYMIYltgPC4wgjAEGsxGIc1OvAV9igHkzMoZdZIQDbIcwXjFW5gCbRxgDwGDCGAAGE8YAMJgwBpgZx5asH2EMAIP5O2Ng7SyPGh+//fUDewLnx8gYGM60K5tOGMMeEzTAuQjjgaykgXVnPXd+hDEADCaMAfaY0SHn4mhq4KyECOw9I2MAGEwYA8BgpqlhTT07veykF2yqOe1iMTJeUQ742Azn+z77PMB6E8YAMJgwBjiNmYg/zO9j7wljABhMGO+BC92KtNUJsNmEMQAM5k+bIPP6Ewhg/WzsyNjUMACrYmPDeCsCGoARhDHwHDZMWWXr+PkUxrBB1nElxhg+S7vLAVwbaDvnLJ7reY6tLJi7uX73uDDCGM5grivBOW2AzKmvczTXz/AmMk0NAIMZGcMF2GokZ9QB4819FsDIGGBFOChqcwnjfebLBsDphDGwK2xosh0+NwvCmJXmiwrrw/f5zHYUxlX1eFU9WFWfq6rjU9uLquq+qvrSdH3p0vK3VtWJqnq0qq7faecBYB3sxtHUP9jdX1+6fyzJ/d19e1Udm+6/o6quTnI0yTVJvivJf6yql3X3t3ahD+yBuR+dCGfis719RrZ7Yy/+tOnGJK+Zbt+Z5D8necfUfld3P53ksao6keTaJJ/agz7siA8bAPtpp2HcST5RVZ3kX3f3HUle0t1PJkl3P1lVL56WPZjk15aee3Jqmw1b0wubtrHifQf22k7D+NXd/cQUuPdV1RfPsmxt0dZbLlh1c5Kbk+SlL33pDrsIwKaY68bzjsK4u5+Yrp+qqo9kMe38taq6fBoVX57kqWnxk0muWHr6oSRPnOF170hyR5IcOXJky8Cem00bTW66ua4QVt25fq++Z+tnU75L2z6auqpeUFV/7NnbSf5KkoeS3JPkpmmxm5J8dLp9T5KjVXVJVV2Z5KokD2z357P6NuXPGFahzlXowyibXDvrYycj45ck+UhVPfs6/767f6Wqfj3J3VX11iRfTvKmJOnuh6vq7iRfSPJMklscSQ3MxaaM0FbVuv/+tx3G3f1bSb5/i/b/leS1Z3jObUlu2+7PBLZnr0aO676C3Mp+1Wy0v1n81yZYYVbIO7eJGwzMjzDeJb7we8/vmGU2VFgnzk1NEgfBAIwkjLdBcAGwm0xTz5QpW7hwq7AR7bvLVoTxzKzCygSA3WWaGoCNtgq7Hjd+ZGzKCC7c6BXXXrAumJ91es+MjNfcKmzxseC9AM5k40fGAHvBhhcXQhgDzNj5hv46TenuxKr+HoTxDKzqh4d524/P1W79DKNM1p19xgADrOoxBKvar3UnjAFgMGHMyrBFDmwq+4yB37cKG0Or0AfYb0bGsGL2e4bAjASMZ2TMxnF0+hh+76vNBtlYRsbsKqMsgAtnZLyHjASATWWj/MIYGQPAYMIYAAYzTc1w25nOMgUGe2+dv2erVpswBtimVVuhM1+mqdlXjrYGeC5hDACDmabmOYxcAfaXkTHAGditwn4RxgAwmDAGgMGEMbCvTP3CcwljABhMGAPAYMKYPWdaEuDshDEADCaMAWAwYczGMn0OrAphDACDCWMAGEwYA8BgwhgABhPGADCYMAaAwYQxAAwmjAFgMGHMEE64AfAHhDEADCaMAWAwYQwAgwljABhMGAPAYMIYAAYTxgAwmDAGgMGEMQAMtu9hXFU3VNWjVXWiqo7t988HgFWzr2FcVRcl+ZdJfjjJ1UneXFVX72cfAGDV7PfI+NokJ7r7t7r7d5LcleTGfe4DAKyU/Q7jg0m+snT/5NQGABurunv/fljVm5Jc391/Y7r/Y0mu7e6fOG25m5PcPN39niSP7mI3Lkvy9V18vZHUsprWpZZ1qSNRy6pal1rOVMef7O4D5/MCF+9uf87pZJIrlu4fSvLE6Qt19x1J7tiLDlTV8e4+shevvd/UsprWpZZ1qSNRy6pal1p2o479nqb+9SRXVdWVVfXtSY4muWef+wAAK2VfR8bd/UxV/XiS/5DkoiTv6+6H97MPALBq9nuaOt39sSQf2++fu2RPpr8HUctqWpda1qWORC2ral1q2XEd+3oAFwDwXE6HCQCDbVQYz/VUnFV1RVX9alU9UlUPV9Xbp/YXVdV9VfWl6frS0X09X1V1UVX9t6r65en+LGupqu+sql+oqi9O78+fnXEtf3v6fD1UVR+qqj86l1qq6n1V9VRVPbTUdsa+V9Wt03rg0aq6fkyvn+sMdfyT6fP1+ar6SFV959JjK1lHsnUtS4/9narqqrpsqW12tVTVT0z9fbiq/vFS+wXXsjFhPPNTcT6T5Ke6+3uTXJfklqnvx5Lc391XJbl/uj8Xb0/yyNL9udbyL5L8Snf/6STfn0VNs6ulqg4m+VtJjnT3y7M4wPJo5lPL+5PccFrbln2fvjtHk1wzPefd0/phFbw/z63jviQv7+7vS/Lfk9yarHwdyda1pKquSPKXk3x5qW12tVTVD2ZxBsnv6+5rkvzTqX1btWxMGGfGp+Ls7ie7+7PT7W9mscI/mEX/75wWuzPJG4d08AJV1aEkr0/yc0vNs6ulql6Y5C8meW+SdPfvdPf/zgxrmVyc5HlVdXGS52dxDoBZ1NLdn0zyjdOaz9T3G5Pc1d1Pd/djSU5ksX4Ybqs6uvsT3f3MdPfXsjg/Q7LCdSRnfE+S5GeT/L0kywcszbGWtyW5vbufnpZ5amrfVi2bFMZrcSrOqjqc5JVJPp3kJd39ZLII7CQvHti1C/HPs/gy/t5S2xxr+VNJTiX5t9OU+89V1Qsyw1q6+6tZbNl/OcmTSf5Pd38iM6xlyZn6Pud1wV9P8vHp9uzqqKo3JPlqd//GaQ/NrpYkL0vyF6rq01X1X6rqz0zt26plk8K4tmib1aHkVfUdSX4xyU9292+P7s92VNWPJHmquz8zui+74OIkP5DkPd39yiT/N6s7jXtW0/7UG5NcmeS7krygqn50bK/2zCzXBVX1zix2WX3w2aYtFlvZOqrq+UnemeQfbPXwFm0rW8vk4iSXZrHr8O8mubuqKtusZZPC+LxOxbmqqurbsgjiD3b3h6fmr1XV5dPjlyd56kzPXyGvTvKGqno8i10FP1RVP5951nIyycnu/vR0/xeyCOc51vKXkjzW3ae6+3eTfDjJn8s8a3nWmfo+u3VBVd2U5EeS/LX+g79HnVsd353Fxt5vTN//Q0k+W1V/IvOrJVn0+cO98EAWM32XZZu1bFIYz/ZUnNPW1nuTPNLdP7P00D1Jbppu35Tko/vdtwvV3bd296HuPpzFe/CfuvtHM89a/meSr1TV90xNr03yhcywliymp6+rqudPn7fXZnFswhxredaZ+n5PkqNVdUlVXZnkqiQPDOjfeamqG5K8I8kbuvv/LT00qzq6+8HufnF3H56+/yeT/MD0PZpVLZNfSvJDSVJVL0vy7Vn8s4jt1dLdG3NJ8rosjkb8zSTvHN2fC+j3n89imuPzST43XV6X5I9ncZTol6brF43u6wXW9ZokvzzdnmUtSV6R5Pj03vxSFtNWc63lHyX5YpKHkvy7JJfMpZYkH8piX/fvZrGSf+vZ+p7FdOlvZvEf4X54dP/PUceJLPZBPvvd/1erXseZajnt8ceTXDbXWrII35+fvi+fTfJDO6nFGbgAYLBNmqYGgJUkjAFgMGEMAIMJYwAYTBgDwGDCGAAGE8YAMJgwBoDB/j854ZoyN7F1NgAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pytorch_metric_learning.samplers import MPerClassSampler\n",
    "import matplotlib.pyplot as plt\n",
    "from utils.OpenSetCows2021 import OpenSetCows2021TrackLet\n",
    "from torch.utils.data.sampler import Sampler\n",
    "from pytorch_metric_learning.utils import common_functions as c_f\n",
    "import random\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy\n",
    "import torch\n",
    "from utils.classWeights import ClassWeights\n",
    "from copy import deepcopy\n",
    "\n",
    "class MPerClassTripletSampler(Sampler):\n",
    "    def __init__(\n",
    "        self, labels, m, batch_size=None, weights=None, length_before_new_iter=100000\n",
    "    ):\n",
    "        self.posSampler = MPerClassSampler(\n",
    "            labels,\n",
    "            m=m,\n",
    "            length_before_new_iter=length_before_new_iter,\n",
    "            batch_size=batch_size,\n",
    "        )\n",
    "        # Check if weights were supplied\n",
    "        if isinstance(weights, numpy.ndarray):\n",
    "            self.weights = torch.as_tensor(weights, dtype=torch.double)\n",
    "        else:\n",
    "            # Equal weights\n",
    "            self.weights = torch.ones(len(labels)) / len(labels)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.posSampler.list_size\n",
    "\n",
    "    def getSets(self):\n",
    "        # Suffle the labels twice to generate the positive and negative lists\n",
    "        c_f.NUMPY_RANDOM.shuffle(self.posSampler.labels)\n",
    "        curr_label_set, curr_label_set_neg = self.posSampler.labels, deepcopy(self.posSampler.labels)\n",
    "        c_f.NUMPY_RANDOM.shuffle(curr_label_set_neg)\n",
    "        return list(curr_label_set), list(curr_label_set_neg)\n",
    "\n",
    "    def __iter__(self):\n",
    "        idx_listPos, idx_listNeg = [0] * self.posSampler.list_size, [0] * self.posSampler.list_size\n",
    "        i = 0\n",
    "        num_iters = self.posSampler.calculate_num_iters()\n",
    "        for _ in range(num_iters):\n",
    "            curr_label_set, curr_label_set_neg = self.getSets()\n",
    "            if self.posSampler.batch_size is not None:\n",
    "                curr_label_set = self.posSampler.labels[\n",
    "                    : self.posSampler.batch_size // self.posSampler.m_per_class\n",
    "                ]\n",
    "\n",
    "            # Assign choice weights to anchors or positives\n",
    "            weightedIndeces = torch.multinomial(self.weights[curr_label_set], len(curr_label_set), True)\n",
    "            curr_label_set = [curr_label_set[index] for index in list(weightedIndeces.numpy())]\n",
    "            # Should we apply weights to the negatives as well? Not sure what effect that would have on the results\n",
    "            # weightedIndeces = torch.multinomial(self.weights[curr_label_set_neg], len(curr_label_set_neg), True)\n",
    "            # curr_label_set_neg = [curr_label_set_neg[index] for index in list(weightedIndeces.numpy())]\n",
    "\n",
    "            # Remove the anchors from the negative set\n",
    "            curr_label_set_neg = list(set(curr_label_set_neg) - set(curr_label_set))\n",
    "\n",
    "            for label in curr_label_set:\n",
    "                idx_listPos[\n",
    "                    i : i + self.posSampler.m_per_class\n",
    "                ] = c_f.safe_random_choice(self.posSampler.labels_to_indices[label], size=self.posSampler.m_per_class)\n",
    "\n",
    "                tex = random.choices(\n",
    "                    curr_label_set_neg,\n",
    "                    k=self.posSampler.m_per_class,\n",
    "                )\n",
    "                # Assert the the anchor does not appear in the negatives list\n",
    "                assert (idx_listPos[i] not in tex) == True\n",
    "                idx_listNeg[i : i + self.posSampler.m_per_class] = tex\n",
    "                i += self.posSampler.m_per_class\n",
    "        return iter(zip(idx_listPos, idx_listNeg))\n",
    "\n",
    "trainingDataset = OpenSetCows2021TrackLet(\n",
    "    \"/Users/as16542/Downloads/3owflku95bxsx24643cybxu3qh\",\n",
    "    \"./utils/opencowsTracklets2021.json\",\n",
    "    maxSequenceLength=5,\n",
    "    transform=None,    \n",
    "    trackletChoiceProb = 0.5,\n",
    "    eval=False,\n",
    "    batchSize=100\n",
    ")\n",
    "\n",
    "# Class weighted sampling\n",
    "# print(trainingDataset.numClasses, len(trainingDataset))\n",
    "sampler = MPerClassTripletSampler(\n",
    "    list(range(155)), m=3,\n",
    "    length_before_new_iter=1000,\n",
    "    batch_size=18,\n",
    "    weights=trainingDataset.getClassWeights('IMF')\n",
    ")\n",
    "# print(len(sampler.posSampler))\n",
    "distribuionPos = numpy.zeros(155)\n",
    "distribuionNeg = numpy.zeros(155)\n",
    "for i in range(100):\n",
    "  pos, neg = zip(*iter(sampler))\n",
    "  for classIdx in pos:\n",
    "    distribuionPos[classIdx] += 1\n",
    "  for classIdx in neg:\n",
    "      distribuionNeg[classIdx] += 1\n",
    "\n",
    "# distribuionPos /= len(sampler)\n",
    "# distribuionNeg /= len(sampler)\n",
    "# fig = plt.figure()\n",
    "# ax = fig.add_axes([0,0,1,1])\n",
    "# ax.bar(list(range(155)), trainingDataset.classFrequency)\n",
    "# plt.show()\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_axes([0,0,1,1])\n",
    "ax.bar(list(range(155)), distribuionPos)\n",
    "plt.show()\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_axes([0,0,1,1])\n",
    "ax.bar(list(range(155)), distribuionNeg)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x1124a3550>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/metricLearning/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1358, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/metricLearning/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1322, in _shutdown_workers\n",
      "    w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/metricLearning/lib/python3.8/multiprocessing/process.py\", line 149, in join\n",
      "    res = self._popen.wait(timeout)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/metricLearning/lib/python3.8/multiprocessing/popen_fork.py\", line 44, in wait\n",
      "    if not wait([self.sentinel], timeout):\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/metricLearning/lib/python3.8/multiprocessing/connection.py\", line 931, in wait\n",
      "    ready = selector.select(timeout)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/metricLearning/lib/python3.8/selectors.py\", line 415, in select\n",
      "    fd_event_list = self._selector.poll(timeout)\n",
      "KeyboardInterrupt: \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [26]\u001b[0m, in \u001b[0;36m<cell line: 30>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     29\u001b[0m distribuionNegative \u001b[39m=\u001b[39m numpy\u001b[39m.\u001b[39mzeros(\u001b[39m23\u001b[39m)\n\u001b[1;32m     30\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m100\u001b[39m):\n\u001b[0;32m---> 31\u001b[0m     _, _, _,  positiveLabel, negativeLabel \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39;49m(\u001b[39miter\u001b[39;49m(trainingDataLoader))\n\u001b[1;32m     32\u001b[0m     \u001b[39mfor\u001b[39;00m classIdx \u001b[39min\u001b[39;00m positiveLabel:\n\u001b[1;32m     33\u001b[0m         distribuionPositive[classIdx] \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/metricLearning/lib/python3.8/site-packages/torch/utils/data/dataloader.py:530\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/metricLearning/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=527'>528</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/metricLearning/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=528'>529</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()\n\u001b[0;32m--> <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/metricLearning/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=529'>530</a>\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[1;32m    <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/metricLearning/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=530'>531</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/metricLearning/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=531'>532</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/metricLearning/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=532'>533</a>\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/metricLearning/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=533'>534</a>\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/metricLearning/lib/python3.8/site-packages/torch/utils/data/dataloader.py:1207\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/metricLearning/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=1203'>1204</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_process_data(data)\n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/metricLearning/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=1205'>1206</a>\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_shutdown \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_tasks_outstanding \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m-> <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/metricLearning/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=1206'>1207</a>\u001b[0m idx, data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_data()\n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/metricLearning/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=1207'>1208</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_tasks_outstanding \u001b[39m-\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/metricLearning/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=1208'>1209</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable:\n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/metricLearning/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=1209'>1210</a>\u001b[0m     \u001b[39m# Check for _IterableDatasetStopIteration\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/metricLearning/lib/python3.8/site-packages/torch/utils/data/dataloader.py:1173\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/metricLearning/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=1168'>1169</a>\u001b[0m     \u001b[39m# In this case, `self._data_queue` is a `queue.Queue`,. But we don't\u001b[39;00m\n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/metricLearning/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=1169'>1170</a>\u001b[0m     \u001b[39m# need to call `.task_done()` because we don't use `.join()`.\u001b[39;00m\n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/metricLearning/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=1170'>1171</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/metricLearning/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=1171'>1172</a>\u001b[0m     \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m-> <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/metricLearning/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=1172'>1173</a>\u001b[0m         success, data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_try_get_data()\n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/metricLearning/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=1173'>1174</a>\u001b[0m         \u001b[39mif\u001b[39;00m success:\n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/metricLearning/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=1174'>1175</a>\u001b[0m             \u001b[39mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/metricLearning/lib/python3.8/site-packages/torch/utils/data/dataloader.py:1011\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/metricLearning/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=997'>998</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_try_get_data\u001b[39m(\u001b[39mself\u001b[39m, timeout\u001b[39m=\u001b[39m_utils\u001b[39m.\u001b[39mMP_STATUS_CHECK_INTERVAL):\n\u001b[1;32m    <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/metricLearning/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=998'>999</a>\u001b[0m     \u001b[39m# Tries to fetch data from `self._data_queue` once for a given timeout.\u001b[39;00m\n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/metricLearning/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=999'>1000</a>\u001b[0m     \u001b[39m# This can also be used as inner loop of fetching without timeout, with\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/metricLearning/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=1007'>1008</a>\u001b[0m     \u001b[39m# Returns a 2-tuple:\u001b[39;00m\n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/metricLearning/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=1008'>1009</a>\u001b[0m     \u001b[39m#   (bool: whether successfully get data, any: data if successful else None)\u001b[39;00m\n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/metricLearning/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=1009'>1010</a>\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/metricLearning/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=1010'>1011</a>\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_data_queue\u001b[39m.\u001b[39;49mget(timeout\u001b[39m=\u001b[39;49mtimeout)\n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/metricLearning/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=1011'>1012</a>\u001b[0m         \u001b[39mreturn\u001b[39;00m (\u001b[39mTrue\u001b[39;00m, data)\n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/metricLearning/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=1012'>1013</a>\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/metricLearning/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=1013'>1014</a>\u001b[0m         \u001b[39m# At timeout and error, we manually check whether any worker has\u001b[39;00m\n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/metricLearning/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=1014'>1015</a>\u001b[0m         \u001b[39m# failed. Note that this is the only mechanism for Windows to detect\u001b[39;00m\n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/metricLearning/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=1015'>1016</a>\u001b[0m         \u001b[39m# worker failures.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/metricLearning/lib/python3.8/multiprocessing/queues.py:107\u001b[0m, in \u001b[0;36mQueue.get\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/metricLearning/lib/python3.8/multiprocessing/queues.py?line=104'>105</a>\u001b[0m \u001b[39mif\u001b[39;00m block:\n\u001b[1;32m    <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/metricLearning/lib/python3.8/multiprocessing/queues.py?line=105'>106</a>\u001b[0m     timeout \u001b[39m=\u001b[39m deadline \u001b[39m-\u001b[39m time\u001b[39m.\u001b[39mmonotonic()\n\u001b[0;32m--> <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/metricLearning/lib/python3.8/multiprocessing/queues.py?line=106'>107</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_poll(timeout):\n\u001b[1;32m    <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/metricLearning/lib/python3.8/multiprocessing/queues.py?line=107'>108</a>\u001b[0m         \u001b[39mraise\u001b[39;00m Empty\n\u001b[1;32m    <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/metricLearning/lib/python3.8/multiprocessing/queues.py?line=108'>109</a>\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_poll():\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/metricLearning/lib/python3.8/multiprocessing/connection.py:257\u001b[0m, in \u001b[0;36m_ConnectionBase.poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/metricLearning/lib/python3.8/multiprocessing/connection.py?line=254'>255</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_closed()\n\u001b[1;32m    <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/metricLearning/lib/python3.8/multiprocessing/connection.py?line=255'>256</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_readable()\n\u001b[0;32m--> <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/metricLearning/lib/python3.8/multiprocessing/connection.py?line=256'>257</a>\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_poll(timeout)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/metricLearning/lib/python3.8/multiprocessing/connection.py:424\u001b[0m, in \u001b[0;36mConnection._poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/metricLearning/lib/python3.8/multiprocessing/connection.py?line=422'>423</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_poll\u001b[39m(\u001b[39mself\u001b[39m, timeout):\n\u001b[0;32m--> <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/metricLearning/lib/python3.8/multiprocessing/connection.py?line=423'>424</a>\u001b[0m     r \u001b[39m=\u001b[39m wait([\u001b[39mself\u001b[39;49m], timeout)\n\u001b[1;32m    <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/metricLearning/lib/python3.8/multiprocessing/connection.py?line=424'>425</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mbool\u001b[39m(r)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/metricLearning/lib/python3.8/multiprocessing/connection.py:931\u001b[0m, in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m    <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/metricLearning/lib/python3.8/multiprocessing/connection.py?line=927'>928</a>\u001b[0m     deadline \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mmonotonic() \u001b[39m+\u001b[39m timeout\n\u001b[1;32m    <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/metricLearning/lib/python3.8/multiprocessing/connection.py?line=929'>930</a>\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m--> <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/metricLearning/lib/python3.8/multiprocessing/connection.py?line=930'>931</a>\u001b[0m     ready \u001b[39m=\u001b[39m selector\u001b[39m.\u001b[39;49mselect(timeout)\n\u001b[1;32m    <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/metricLearning/lib/python3.8/multiprocessing/connection.py?line=931'>932</a>\u001b[0m     \u001b[39mif\u001b[39;00m ready:\n\u001b[1;32m    <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/metricLearning/lib/python3.8/multiprocessing/connection.py?line=932'>933</a>\u001b[0m         \u001b[39mreturn\u001b[39;00m [key\u001b[39m.\u001b[39mfileobj \u001b[39mfor\u001b[39;00m (key, events) \u001b[39min\u001b[39;00m ready]\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/metricLearning/lib/python3.8/selectors.py:415\u001b[0m, in \u001b[0;36m_PollLikeSelector.select\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/metricLearning/lib/python3.8/selectors.py?line=412'>413</a>\u001b[0m ready \u001b[39m=\u001b[39m []\n\u001b[1;32m    <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/metricLearning/lib/python3.8/selectors.py?line=413'>414</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/metricLearning/lib/python3.8/selectors.py?line=414'>415</a>\u001b[0m     fd_event_list \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_selector\u001b[39m.\u001b[39;49mpoll(timeout)\n\u001b[1;32m    <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/metricLearning/lib/python3.8/selectors.py?line=415'>416</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mInterruptedError\u001b[39;00m:\n\u001b[1;32m    <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/metricLearning/lib/python3.8/selectors.py?line=416'>417</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m ready\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from pytorch_metric_learning.samplers import MPerClassSampler\n",
    "import matplotlib.pyplot as plt\n",
    "from utils.OpenSetCows2021 import OpenSetCows2021TrackLet\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy\n",
    "from random import choices\n",
    "\n",
    "trainingDataset = OpenSetCows2021TrackLet(\n",
    "    \"/Users/as16542/Downloads/3owflku95bxsx24643cybxu3qh\",\n",
    "    \"./utils/opencowsTracklets2017.json\",\n",
    "    maxSequenceLength=5,\n",
    "    transform=None,    \n",
    "    trackletChoiceProb = 0.5,\n",
    "    eval=False,\n",
    "    batchSize=100\n",
    ")\n",
    "\n",
    "sampler = MPerClassTripletSampler(\n",
    "    list(range(23)), m=5, length_before_new_iter=len(trainingDataset),\n",
    "    batch_size=100\n",
    ")\n",
    "\n",
    "\n",
    "trainingDataLoader = DataLoader(\n",
    "    trainingDataset, batch_size=100, num_workers=1, shuffle=False, pin_memory=True, sampler=sampler\n",
    ")\n",
    "\n",
    "distribuionPositive = numpy.zeros(23)\n",
    "distribuionNegative = numpy.zeros(23)\n",
    "for i in range(100):\n",
    "    _, _, _,  positiveLabel, negativeLabel = next(iter(trainingDataLoader))\n",
    "    for classIdx in positiveLabel:\n",
    "        distribuionPositive[classIdx] += 1\n",
    "\n",
    "    for classIdx in negativeLabel:\n",
    "        distribuionNegative[classIdx] += 1  \n",
    "\n",
    "distribuionNegative /= 100\n",
    "distribuionPositive /= 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = (15, 5)\n",
    "# plot data in grouped manner of bar type\n",
    "print('Positive Sampling')\n",
    "width = 0.40\n",
    "x = numpy.array(range(23))\n",
    "ax = plt.axes()\n",
    "\n",
    "plt.bar(x-0.2, distribuionPositive, width, color='cyan')\n",
    "plt.bar(x+0.2, distribuionNegative, width, color='green')\n",
    "\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(['$C_{{{}}}$'.format(i) for i in range(23)])\n",
    "\n",
    "plt.xlabel(\"Individual\")\n",
    "plt.ylabel(\"Number of Samples\")\n",
    "plt.legend([\"Positive\", \"Negative\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "positiveLabel\n",
    "weights = compute_class_weight(class_weight = 'balanced', classes = numpy.unique(classFrequency), y = classFrequency)\n",
    "population = list(range(23))\n",
    "\n",
    "negSamples = []\n",
    "for label in positiveLabel:\n",
    "    w, p = list(weights), \n",
    "    w.pop(label)\n",
    "    p.pop(label)\n",
    "    negSamples.append(choices(p, w)[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(range(23)).pop(1)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a35bd2a748ff812196078b530039d66aaa336851f47ca82b0a06ab1bf96aa2d4"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('metricLearning': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
